from __future__ import annotations

from dataclasses import dataclass
from typing import Protocol, Sequence
from urllib.parse import parse_qs, urlencode, urlparse, urlunparse

from bs4 import BeautifulSoup

from .models import Item


class TranscriptProvider(Protocol):
    name: str

    def fetch(self, item: Item, urls: Sequence[str]) -> dict[str, str]:
        ...


@dataclass
class FakeTranscriptProvider:
    name: str = "fake"

    def fetch(self, item: Item, urls: Sequence[str]) -> dict[str, str]:
        title = item.title or f"Item {item.id}"
        if not urls:
            urls = [item.canvas_url or f"item:{item.id}"]
        return {
            url: (
                f"Transcript for {title}\n\n"
                "This is placeholder transcript content generated by the fake provider."
            )
            for url in urls
        }


class PanoptoTranscriptProvider:
    name = "panopto"

    def fetch(self, item: Item, urls: Sequence[str]) -> dict[str, str]:
        if not urls:
            raise ValueError("Panopto provider requires at least one URL")
        try:
            from panopto_transcript_scraper import get_transcripts
        except ImportError as exc:  # pragma: no cover - optional dependency
            raise RuntimeError("panopto_transcript_scraper module not available") from exc

        normalized_urls = [normalize_provider_url("panopto", url) or url for url in urls]
        transcripts = get_transcripts(normalized_urls)
        cleaned = {url: text for url, text in transcripts.items() if text}
        if not cleaned:
            raise RuntimeError("Panopto transcript could not be retrieved")
        return cleaned


class ZoomTranscriptProvider:
    name = "zoom"

    def fetch(self, item: Item, urls: Sequence[str]) -> dict[str, str]:
        if not urls:
            raise ValueError("Zoom provider requires at least one URL")
        try:
            from zoom_transcript_scraper import get_transcripts
        except ImportError as exc:  # pragma: no cover - optional dependency
            raise RuntimeError("zoom_transcript_scraper module not available") from exc

        transcripts = get_transcripts(list(urls))
        cleaned = {url: text for url, text in transcripts.items() if text}
        if not cleaned:
            raise RuntimeError("Zoom transcript could not be retrieved")
        return cleaned


def infer_provider_from_url(url: str | None) -> str | None:
    if not url:
        return None
    lowered = url.lower()
    if "panopto" in lowered:
        return "panopto"
    if "zoom" in lowered:
        return "zoom"
    return None


def normalize_provider_url(provider: str | None, url: str | None) -> str | None:
    if not url or not provider:
        return url
    provider = provider.lower()
    if provider == "panopto":
        try:
            parsed = urlparse(url)
            if "panopto.com" not in parsed.netloc.lower():
                return url
            query = parse_qs(parsed.query)
            pid = (query.get("id") or [None])[0]
            if "Viewer.aspx" in parsed.path and pid:
                return urlunparse(
                    (
                        parsed.scheme,
                        parsed.netloc,
                        "/Panopto/Pages/Viewer.aspx",
                        "",
                        urlencode({"id": pid}),
                        "",
                    )
                )
            if "Embed.aspx" in parsed.path:
                return urlunparse(
                    (
                        parsed.scheme,
                        parsed.netloc,
                        "/Panopto/Pages/Viewer.aspx",
                        "",
                        urlencode({"id": pid}) if pid else parsed.query,
                        "",
                    )
                )
        except Exception:
            return url
    return url


def resolve_provider(item: Item, provider_override: str | None = None) -> TranscriptProvider:
    provider = (provider_override or item.provider or "").lower()
    if provider == "panopto":
        return PanoptoTranscriptProvider()
    if provider == "zoom":
        return ZoomTranscriptProvider()
    return FakeTranscriptProvider(name=provider_override or item.provider or "fake")


def extract_media_entries(html: str) -> list[dict[str, str]]:
    soup = BeautifulSoup(html or "", "html.parser")
    entries: list[dict[str, str]] = []
    seen: set[tuple[str, str]] = set()

    def add_entry(provider: str, url: str) -> None:
        normalized_url = normalize_provider_url(provider, url) if provider == "panopto" else url
        if not normalized_url:
            return
        key = (provider, normalized_url)
        if key in seen:
            return
        seen.add(key)
        entries.append({"provider": provider, "url": normalized_url})

    candidate_attrs = []

    for meta in soup.find_all("meta", attrs={"property": "og:url"}):
        content = meta.get("content")
        if content:
            candidate_attrs.append(content)

    for attr in ("href", "src", "data-src"):
        for tag in soup.find_all(attrs={attr: True}):
            candidate_attrs.append(tag.get(attr))

    for raw_url in candidate_attrs:
        if not raw_url:
            continue
        provider = infer_provider_from_url(raw_url)
        if not provider:
            continue
        add_entry(provider, raw_url)

    return entries

