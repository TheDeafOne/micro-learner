The core of machine learning and
many historical analytical problems
is supervised learning.
In this module, we will
study supervised learning
as the major machine-learning methodology.
Where a model is generated by
feedback using
the ground truth or dataset labels.
A cost function or a criteria is
utilized to fit the data to the model.
Ideally,
the most competitive supervised
learning algorithms
are based on sound mathematical principles,
such as optimization,
statistics, or function approximation.
We will implement a Naive Bayes algorithm
from scratch using NumPy,
mat and sci-fi statistics libraries.
We will demonstrate its performance on
an artificially created dataset that we will
examine the classification boundaries
of several classifiers,
including our implementation,
in order to have
a good understanding of
the behavior of classification models.
In the following sections,
we will present a router's
news text classification problem
using TFIDF features.
And finally, we will classify
StackOverflow forum posts
on 20 different languages.

Dear students.
In this module, we will
look at supervised learning.
If you have worked in
machine learning before,
you will immediately know that
supervised learning is one of
the most important concept
applications in machine learning.
Supervised learning requires the ground truth
to be known beforehand.
The algorithm, the approach
works using the feedback
from the ground truth that we have.
We can assign if a particular hypothesis
is true or false using the ground truth.
And then we can collect
the amount of the error
using all the hypotheses we have.
E.g. in the past module,
I mentioned the simplest classifier could be
the algorithm that
assigns everything to zero.
Thus the hypothesis.
Well, it is also falsifiable.
I can test if that confirms
their particular data points or not.
Meaning if it's true for that data point,
yes or no, I have the ground truth.
I can find out any condition you can
come up with can be a hypothesis.
The set of all the conditions are
hypotheses which
creates some buildup the actual model.
In a way we're trying to find
all the hypotheses that are falsifiable,
which results in the minimum error or
maximum reward criteria, which we will see.
In supervised learning, there are
two categories,
classification and regression.
Classification is
the prediction of the categories.
Will it be warm today?
Yes, no, the categories are yes or no.
Will patients die from
the cancers in
the following two years? Yes or no?
Or we can say our category set is lowest,
low, medium, high,
highest than there are five categories.
Sometimes a machine learning algorithm can
be binary by design. Naturally.
In that case, we will
set n choose two classifiers.
If there are five categories,
I've built five, choose
two number of classes,
which is five times 4/2 number
of classifiers to come
up with the actual model.
The error for
a particular data point would be
the result of all those
five choose two classifiers.
You can, we can do majority voting.
We can accumulate the error and assign
a particular label for a datapoints.
Of course, the details are
all in the algorithms.
We will see in
the following sections and modules,
how we build five choose two classifiers.
For our purposes, most of
these things are in the libraries, e.g.
if I use an SVM classifier,
which is naturally
a binary classifier based on perceptrons.
The library builds five
choose two SVM classifiers and then
automatically does a majority voting
and then results or
the actual predicted label
for a particular data points.
Now, let's look at perceptron.
Perceptron was invented many decades ago.
Perceptron is the building block
of neural networks and
also it was an inspiration
for the support vector machines.
Perceptron simply attempts to find
a hyperplane which divides
the data points into two categories.
Natural, it's a binary classifier,
the wave it's train.
The perceptron is based on the error,
the accumulation of the error
for each predicted data points.
Thus, the error or cost
function is the summation of
all the actual class labels
01 and the predicted class labels, again 01.
The cab historically is
the notation for the estimators variable.
Also I had n data points.
This is our syntax or these are
standard in our dataset matrix.
We have n data points,
which is the number of rows.
And we have m features or dimensions,
which are the number of attributes or
the number of columns in that matrix.
The hyperplane naturally Is of m dimensions.
In the textbook, it is
shown how to train a perceptron.
Now, before looking at
the perceptron implementation in our widget,
let's shortly, quickly mentioned
the Naive Bayes and linear regression.
Naive Bayes is a probabilistic approach
based on the Bayesian rule.
We, in this module,
we have an example implementation of
main base and linear regression is
the counterpart of
the supervised learning where a prediction
of a continuous or
real valued variable is achieved.
So in a way, classification
and regression are counterparts.
Classification, we are
classifying into categories, regression.
We're trying to find an actual value.
Note that there is
no probability associated in regression.
It is in it's simplistic terms, a curve fit,
we will see linear regression
and other regressions, e.g.
logistic regression classifier
based on regression.
In the following modules.
In this module, we will concentrate on
supervised learning and
categorical classification.
For the sake of completeness,
the linear regression formula is like this.
We minimize this particular error.
Note that the difference
between this cost function,
the cost function of
a perceptron is in the details here.
The values are 010 or one, right?
It's the binary classifier,
but here the numbers
are actual numerical values.
So this predicted has a huge range,
minus infinity to plus infinity.
It can be anything. And the
actual is again like that.
If I set up the problem
using a line fit than it has
a direct solution using
the linear regression optimization
and solving for
the parameters b0 and b1 be
zero as the offset b1 as the slope.
We can find out by minimizing this error,
the actual b0 and
b1 to come up with that line,
the details will be in the following modules.
Now let's look at the
perceptron visualization
using our widgets.

When it comes to machine learning algorithm
setting the math,
it's called application and the
visualization of it is so much helpful.
So here's the general Perceptron
machine visualization.
To tease out its parameters
and its classification performance.
In a 2D space.
I downloaded the
perceptron visualisation widget
to my Anaconda environment.
And then it's starting state.
We cannot run the widget.
Notebook cannot run the widget because
the state is not found.
Well, I have just to rerun the cells.
Now. I know that perceptron
isn't hyperplane in n dimensions.
In this fidget, we're
visualizing it in two-dimensions.
Now, we will come to the details
of the implementation later.
But first let's understand how it works.
Okay, Now I ran the widgets and look at
here we have two features,
x1 and x2 in our x matrix,
there are two columns, okay?
Now the hyperplane is controlled
by B and W zero and w1,
exactly like in this equation.
In here, w is the normal to that hyperplane.
Here the red arrow arrows
show the normals, but of course,
the actual normal is
in the middle of this hyperplane,
look in orthogonal
from that hyperplane outwards.
So w is the normal and B is the offset.
My hyperplane is defined by,
by this wx plus b equals zero.
All the x points are the hyperplane,
are on the hyperplane.
Well, you see dx
here for the data points for classification.
And the x here are from the same space.
It's the two-dimensional feature space.
And these x's define this hyperplane.
And those x's are
all the points in this space.
And naturally in this equation,
wx plus b equals zero is the hyperplane.
But here, w x plus b greater than
zero or less than zero
are the data points around it.
For the moment, just forget about
how we find w and b.
But let's see how the hyperplane
divides the space into two,
marking all the ones on
the left or less than zero,
S class zero and all the ones
on the right are greater
than zero as class one,
for the ease of visualization,
I set theta based on W's.
I automatically compute it so
that we can have
a single variables to control.
Theta is the angle.
Now, as I move it,
the hyperplane positions itself exactly.
E.g. -1.55 is pi over 290 degrees.
So it's looking downwards.
Zero is the starting 0.0 rad.
And pi over 2 rad,
it rotated 90 degrees, or Pi over two.
Theta here is in radians and B is the offset.
You see how it behaves.
And by the way, for each of
the value that I play individually,
declassification is automatically done.
All the points greater than zero or
less than zero are
marked with the correct classifications.
This visualization
does everything a classifier does.
Let's look at the implementation details.
This is the hyperplane given
the data points and given the W, the normal,
and the offset, it is returning
the other feature that is on the hyperplane.
This is used to find out given x1 and x2,
the reason is all visualization.
It is of course,
intentionally written that way
so that we can visualize how
the hyperplane divides the space into
two and can be used as a classifier.
Perceptron is the actual classifier,
and it's the same, same thing.
Given x w be.
It basically computes this fx.
That's my classifier.
If the dot product of
x w, like in this equation,
plus b is greater than zero,
return one exact lactose, or returns zero.
So perceptron implements effects.
And this is the beauty of num pi.
This dot is from non pi x, w are arrays.
This would work for any dimension.
In this case,
it's two-dimensional feature space.
If I had n dimensions,
I wouldn't change the perceptron.
It like MATLAB, it automatically computes.
By solving, by computing
the correct erase here.
Now the rest is
the widget and the visualization.
We have a figure, we have an array
of w based on theta.
Theta is controlled here.
So basically, the W
is a normal of length one.
It's based on cosine and sine theta.
Its length is one and it is in the middle,
turning as our control data,
I'm using W as my normal,
which represents the hyperplane plus B.
Of course, now X1 is
all the data points in this area,
basically linear space two
times sine theta one x1 minimum.
Similarly sine x1 maximum
and I have 11 number of segments.
And here x, y minimum,
X1 maximum for both features
are provided minus ten to ten.
It is also reflected here,
basically using all the data points
in my feature space,
I'm classifying all of them.
There are 24681011 data points
in this mesh because I set it to 11 here.
And I'm basically, I'm populating all of
them using these linear space.
I'm finding the hyperplane.
You using that hyper.
It is solving.
This is solving clearly this equation, right?
Given X1, I'm finding out
x2 by solving this equation.
This would work for two dimensions easily.
If you want to build this
in three-dimensions,
you have to provide X1 and X2 to find x3,
plot them, and are now classify them again,
X1, X2, meshgrid is this whole thing.
Find out the actual classification.
My perceptron is here, P1,
P2's are these list comprehensions,
zipping, flattening and unzipping for x, y.
Finding out the perceptron for all those,
all the negative ones are drawn in P1.
All the posterior ones are drawn in P2.
And P1 and P2 are marked by
the small lowercase 0 and plus sign.
All these are visualization.
We are classifying all this space,
all these points.
So perceptron behaves in this manner.
And it's the building block
of neural networks,
deep learners, and everything else.
This is of course a
linear one, the hyperplane,
the combination of all these,
as we will see in a neural network,
is used to implement serves or vaguely space.
The counterpart in
the support vector machine is the kernel.
To create the wiggly space.
We will also see that in our current module.

Now let's look at an implementation
of Naive Bayes classifier.
It's one of the simplest classifiers.
It's not the weakest Naive Bayes classifier
is based on sound principles.
And a few decades ago,
it was one of the basic classifiers.
It uses the Bayes rule.
We're computing the posterior probability by
likelihood class prior
probability and predicted probability.
Now, here's an implementation.
First, let's create
the dataset in these cells
were making use of the make
blobs five classes with two features.
And you see, it's not that bad,
It's not an easy problem.
There are 12345 categories,
and many of them are overlapping.
They're centroids are different.
E.g. the centroid of
this light green is here.
The centroid of these are in other places.
If the centroids were to close,
those two classes would be mixed up easily,
as you can imagine, e.g.
if you cluster these,
you can cluster by looking at the density.
These five, this has a different density,
the SAS titled density.
But if two of them overlap each other than,
we cannot differentiate
between those two clusters.
Similarly, Naive Bayes is
relatively a simple classifier,
not, would not be able
to differentiate between those two.
Centroids are given as minus three,
minus three in this fashion.
They are not overlapping,
they're nicely apart.
The number of data points are 100, 500,
1000s, and the clusters
standard deviation is like here.
So this is the first one,
standard deviation two, these are tighter,
these are easier to classify.
Of course, the big one is five.
It's spread out a lot.
Well, how much classification
accuracy would you expect?
The random performance would
be 20 per cent, right?
So probably if I achieve
1995 per cent accuracy
across validation accuracy,
I would be happy, right?
Let's see the performance of
Naive Bayes in this dataset.
First, let's look at
the implementation of the Naive Bayes.
And of course, Scikit-learn
has a Naive Bayes,
which is SKLearn Naive Bayes,
Gaussian Naive Bayes.
There are many variations of it.
There's also a multinomial version of it,
which is multi-class Naive Bayes,
Gaussian Naive Bayes is not, not a nominal.
Let's see how we
implement the customer in base.
The variables we need
are these three likelihood class,
prior probability and predicted probability.
If we assume numerical input,
we can use the stats function
norm pdf to come up with those probabilities.
If the input data is categorical,
we learned to one-hot
encode them in module three.
And we can also build a custom Naive Bayes,
totally nominal without one-hot encoding.
But building a multi-dimensional array
and storing each of
the categorical input variable.
Interestingly, some classifiers
are good with numerical.
Some classifiers are good with nominal.
E.g. support vector machines,
neural networks,
regression are all numerical or clustering.
Most of the clustering are all numerical.
However, Naive Bayes can work with numerical.
It can use those numerical
values to build a PDF.
But inherently, actually it's
a nominal classifier because
it computes the probabilities of the numbers.
If I have categorical or nominal variables,
than it's easier to
build those probabilities.
E.g. random forest uses
nominal variables
because it's computes the entropy,
which is based on the probability of each
of the value of the variable,
but it doesn't matter.
All of these can be converted to each other.
We can convert numerical
to binominal by binning,
we can convert nominal to
numerical by one-hot encoding.
And all of these are done
automatically in Scikit-learn libraries,
of course, or
Weka machine learning libraries.
Now, customary ways is a class.
It uses the pnorm function
PDF in order to compute the PDF.
And this interface,
this API is same
with the scikit-learn library.
We have a fit, we have a prefix.
When we create the custom Naive Bayes,
it initializes certain things.
It uses capital N, M,
C n, number of
data points, number of features,
number of classes, number of categories,
and prior, predictor
and likelihoods, variables.
All of our, all of these are set to none.
If you make a mistake
and it remains as none in the program,
you will see an error right away.
All the variables,
likelihood, prior predictors.
We have prior predictor likelihood.
Some of these are easy to compute.
Some of these are a
little bit more complicated
looking and there's some error check
in the fit function.
All of these are populated.
We have, we always have
the self variable for a Python class,
the x train and y train.
It's the same API pulled the shape,
compute by AMP unique the y train.
Ideally class numbers should
start from zero, doesn't have to.
I'm just computing the number of classes,
number of categories here.
If the minimum y train is not zero
and the maximum is not CN
minus one, it gives an error.
When you program something like this,
It's always good to place constraints.
Here.
I'm constraining the class numbers
starting from zero to c n minus one.
This is typical in most of the cases,
even though it would work with different CN.
Since I'm using the C in Sian as an index,
actually, I prefer to start from zero.
It's an implementation detail.
If this is not the case,
then you can map
your classes to zero and rest.
And of course it's an integer.
If I have five classes,
it will go 0-401234.
Prior is the bincount of the y train
divide by self and it's
basically a probability mass function.
Remember, prior is
the class prior probabilities,
how many data points belong,
or I expect in my training dataset
to belonging to class 0123, e.g.
if I use all my data for training than
the priors would be
directly correlated to the number of samples.
The prior of class five would
be 1,000 divided by the total.
The prior of class,
first-class would be 100 divided by total.
So that's the class prior probability.
Predicted probability is a bit different.
It has to be a PDF, right?
Prior probability,
it's the probability mass function.
There is no standard deviation.
But for the predictor there is.
And all of them are
coming from the training dataset.
Basically, pull all the training
fit my norm function,
it does the rest.
I'm fitting a PDF
for every feature. How many features?
I have two, then I will have a PDF.
For each of those features,
I will have two PDFs.
Those are the predictor variable
which is based on the features.
If I have five features
than I will have five predictors.
Notice that Naive Bayes
assumes each
of those features are independent,
uncorrelated, because that's why I'm
building an individual PDFs
for each one of them.
If they are joined.
If my assumption is incorrect,
then here I'm doing something wrong
because when I build my PDF for future one,
I'm dismissing the effect of future too.
That's Naive Bayes.
It's not neural network,
so it's limited, but it's also very fast.
You, we will see that now the likelihood is
the dictionary of all the features per class.
Some classes rely on
certain features more than the others.
So this is taking care of
those details are in the Bayesian rule.
I'm computing X given the class,
I computed the prior,
the predictors, the first one was prior,
write the probability of C. Second one was
predicted probability of or
PDF of each feature.
Now, the third one is
the PDF of the feature given the class,
how many do I need to features five classes.
Now let's look at the program again.
For each of the class,
for the likelihood class,
it's an array of PDFs, again, m features.
So for each class, I have two features.
Pdf class zero to v df,
class 12 PDFs class to, to PDF.
I have ten PDFs.
When I build all these with the fit,
I will have three probability functions.
One of them probability of mass,
the other are arrays of PDFs.
And I'm ready for any kind of prediction.
For the prediction, basically,
I apply this ratio for each of the class,
compute these, pick the maximum one.
That's how it works for each
of the data points in tests.
Compute the likelihood,
compute the predictor,
and all of these are array operations,
and then take the product
of the future probabilities.
We have to do this because
each feature is independent,
we cannot add them.
We have to multiply them
to compute the final probability.
We're multiplying per
feature and we're picking
as the predicted y as the argmax of those Ps.
Remember each of
these Pi's r vector I'm computing.
For each data point,
I'm computing P in the array of classes.
I would suggest running this program using
PyCharm debugging and seeing how it works.
I'm picking
the white prediction and of course,
I'm populating here for
each of the data points in test,
taking the argmax of that probability,
which is computed as an array for each of
the class and assigning
down from my prediction.
That's it.
Now, the first thing you should do to test
such a classifier that
you implemented manually.
The first thing you have to do
is reclassification.
Basically a train with everything you have,
test with everything you have.
It's the same API.
This is our customer value-based
fits my X1, y1,
which is computed before
looking at the y prediction,
look at the accuracy score.
Wow, reclassification is 97 per cent.
Of course it is slower than
the library because everything
is manually computed here.
There are faster methods,
which is out of scope of this course.
So probably two box right?
Now let's do 10-fold cross-validation.
We implemented this to
do the 10-fold cross-validation
we are evaluating
for classifiers are customary.
Ebay's Gaussian NB from the scikit-learn
library support vector machine
using a linear kernel.
Basically it's a perceptual machine and
the support vector machine using
an RBF kernel and compare all of them.
97% stratified, cross-fold, wide
stratified because
the classes are unbalanced.
I have 100500500501000, pretty unbalanced.
For a balanced case,
it would be 100100100100100 class
prior probabilities are not equal to
each other, so it's unbalanced.
97%, 97 per cent.
So our customer base is being pretty good.
It's a good implementation
in terms of correctness,
linear, not that good.
Note that linear SVM is
a very generalized classifier.
It's not a bad thing.
You have a low performance and RBF.
It's also generally enough,
SVMs are in general,
generalizable classifiers.
96, not bad.
This shows that this difficult problem
here can be solved with
one of the simpler classifiers,
Naive Bayes, in a very reliable fashion.
We're able to have achieved
97% accuracy
based on 10-fold cross-validation,
which is an excellent evaluation methods
on five classes.
Saw, in my opinion,
this is a big success.

Now let's see how
these classifiers behave in general.
All classifiers
generate some decision boundary, e.g.
our Naive Bayes is able to build a PDF here,
a two-dimensional PDF based on x1 and x2,
and also a PDF here,
a PDF, a PDF here,
and a PDF here.
So how do these classifiers work?
How do they classify?
Remember the perceptron widgets,
basically fitting an hyperplane in between
the data points and then
dividing the space into two.
Well,
the other classifiers do similar things.
This program here, plot decision boundary,
basically demonstrates
how these classifiers behave.
We have two features, x1 and x2.
We have four classifiers
that we are playing with.
Customer value-based Gaussian NB
from the scikit-learn library, SVM,
linear SVM RBF, look at,
look at all the decision
boundaries that they built.
A circular PDF, Circular, Circular, Circular.
If I give different standard deviations
to F1 and F2,
feature one and feature two, or X1,
X2, these would be ellipsoid.
And as you see,
the way customer base,
the PDFs and the Gaussian NB bills,
they're exactly the same.
This is just faster SVM linear.
Svm RBF behave totally different.
Svm linear uses these hyperplanes for
this little class and
places some other hyperplanes to other e.g.
that's why SVM linear
mixed a lot of mistake because look,
in this region, light green is winning.
But in this region,
all the light greens are classified for dark.
So I'm losing all these points.
They will go to error.
Similarly, all these around
the orange ones are classified as orange.
I'm losing them for the light green.
Similarly here.
Similarly here. That's why
SVM linear is making more error.
However, we might prefer this.
This is a very, very general classification.
I divided up the space,
the two-dimensional feature space,
into these sections.
And then I'm building
my classifiers upon internally.
Five choose two classifiers are built,
but this is the dividing,
this is the combination
of the dividing hyperplanes.
Now let's look at
the RBF, completely different.
It uses a different kernel.
I do not have hyperplanes anyway anymore.
They are not planes anymore,
but they are wiggly.
And the Gamma parameter two is controlling
the big willingness to classify this data.
When I look at here,
all the ones in
this area belonged to dark green,
orange are the ones,
and the rest is light green.
So RBF is making less mistake,
but it's not probable stick,
it is still making some mistake.
However, it doesn't assume
anything SVMs builds
according to the data we have
custom Naive Bayes assumes the data,
the underlying data has
normal distribution and they're
independent of each other, as you will.
Let's see, let me use different datasets,
not deployed datasets like this.
This is a toy dataset.
It's very easy to classify this.
It doesn't reflect the world out there.
The data alter the data files,
datasets that we generate in
our daily lives are
not well-mannered like this,
but I need classifiers
like these two nucleus
via the real-world database.
We will see more on
the generalization in the following modules.
When we come to regularization,
we will see that these two are
not that great because
they are not general enough.
But these two are
better because they are more general.
We want generality in a classifier.
We want less overfit.
We do not want underfit.
That's not enough training,
but we definitely do not want to,
want to overfit is
the utmost important concepts
that we're following
in our supervised learning.

Let's see two real-world examples.
Both of them are text processing
and text classification problems.
But their real-world problems.
The first one, the famous dataset routers,
we will use NLTK library and
NLTK corpus of routers is a small version,
but still it's good enough
and big enough for our purposes.
Now, we will use TF-IDF
metric as the features.
We do not have to code anything.
Everything is already in the libraries.
When we look at the data,
we will have these classes.
There are 90 categories.
The number of documents or 10,000.
Each document is a few
sentences with a title.
This data is old.
This is a representation of the data.
We're printing only the first 150 characters.
So some title and some texts.
This is e.g. assigned to
other category by ourselves. This is green.
This is crude. Of course,
this dataset is annotated,
meaning somebody or a team
wins over the data and assigns labels.
But look, it's a difficult problem.
The number of categories is 90.
A number of documents is
10,000 with lots of words.
In order to small
our problem size, make it smaller.
We're assigning the documents
into some bigger categories.
When we sort them, we see
the category earn 3,900 documents.
It goes like this.
We will pick the first
top five categories and
then assign the rest of
the documents into others in these cells.
So now we have six categories
and these classes,
this is pre-processing write.
The original dataset doesn't suit
immediately to me because 90 categories,
too many in practice routers.
It is used for clustering analysis, e.g. a.
Short summary about TF-IDF.
Basically, it uses every word as a feature.
How many words you have?
100,000, 100,000 features in your X matrix,
there are 100,000 columns.
Look at the frequency of
those words in your document.
That's your future value.
In order to normalize that,
we are using how many times
you see that word in
the totality of the documents
and normalizing that e.g.
d. Is considered as a stop word.
You see everywhere
the inverse document frequency
of D would be there very high, right?
Because they D shows
up in almost all documents done,
we are using inverse document frequency
to normalize the actual frequency of d.
Suddenly the TF-IDF value
of D goes down. That's what we want.
We want meaningful, important terms like
alien inflation to have an high TF-IDF,
because I will use TF-IDF to classify
my documents into six categories.
Now these cells are just to
map the documents into categories,
converts the categories index
from labels like text into numbers,
and also pull the documents,
pull the categories like this.
And I'm looking at here.
Now, the rest is
building the pipeline of those classifiers.
I'm using k-fold evaluation,
always the most reliable evaluation method.
We are using TF-IDF
vectorizer on the dataset.
It's pretty advanced vectorizer.
You don't have to do
a TF-IDF generator on your
own to work on this text processing problem,
we pulled the TF-IDF vectorizer.
Our X data matrix is
1000788 documents and features is 30,000.
Tf-idf vectorizer inside gets,
gets rid of the junk words, stopwords.
It does a lot of good processing for us.
And then generate the X matrix for us.
It is hard to beat
TF-IDF vectorizer on your own.
We will use support vector machines,
linear and RBF,
and then we will use Naive Bayes,
and then we will
use random forest classifier.
So we have five total classifiers,
including the logistic regression,
more or less, for any kind of problem.
When you start, you should try Naive Bayes,
random forest, logistic regression,
support vector machines and neural networks.
These are the most important classifiers
and they behave a bit differently.
Most of them will generate similar results.
And then it's a matter of
data science task to find out
what kind of pipeline to use
generally support vector machines are slower.
Logistic regression is slower,
deep learner is slower.
But Naive Bayes is very fast.
Random force this fast,
it can be parallelized.
In this case, e.g. there are
Eight cores I'm using for
the random forest and
then it is running in parallel.
These are the results.
You have to run these on your own.
Some of them are slow for
the RBF support vector machine,
which has the kernel computation,
cannot be parallelized unfortunately,
or at least this library doesn't have it.
It could be using those
k-fold, five choose two.
In this case, six choose
two classifiers in parallel is possible,
but the library doesn't have it.
It takes 16, almost 7 min.
So you should see 10 min on your machines.
But I would like you to run this and see
what to expect in
a real-world problem, it difficult problem.
This matrix is huge, 10,000 times 30,000.
You will need a lot of memory to use. This.
X is stored as sparse matrix.
Saw, things are taken care of for you.
Linear support vector machine works very
fast because it's just hyperplanes know,
Weekly Journal competition for 10 s.
And look at the performance is very high.
Naive Bayes, not bad.
80 per cent.
As we expect.
Support vector machine will
always be many ways,
no matter what in
real-world data, but it's fast.
The first thing I
would try would be naive Bayes,
because it's relatively reliable, it's fast.
Not that super performer.
But I will give an idea
about the problem size.
Random forest is very reliable,
It's very strong approach
83% logistic regression is
very slow compared to these two,
but it's a reliable classifier.
It works well. And of course you have to
play with the parameters like e.g.
the solvers, number of iterations,
and its accuracy is 93%.
In this case, linear SVC is clearly
the best performer in most
of the texts processing
applications with TF-IDF.
The first thing you should try
for high performance is
support vector machine with
linear kernel, hyperplane kernels.
In this case, linear SVC function
is different from SVC.
Linear SVC is optimized
for linear support vector machine.
This SVC can be used
with kernel equals linear.
It will be the same thing,
but it would be very slow because it's
not as optimized as linear SVC.
So that's it.
In this case, I was able to
classify my documents into six categories.
And my performance
10-fold cross-validation performance was 94%,
which is a good one.
It is much, much better
than 1/6 random performance,
and it does in a very good time, 13 s,
including the feature extraction, extraction.
This pipeline builds
the count vectorizer TF-IDF transformer,
and the classifier into a single pipeline,
in my opinion, is very,
very fast and efficient.
Now, the last example,
again takes processing
is programming language detection
from forum posts using StackOverflow data.
This is a more difficult problem
with 20 categories.
Again, I will use
TF-IDF generator for features, some examples.
This is posted C-sharp, tag is C-sharp.
Well, of course, someone has
to go over all these labels,
ground-truth to be
used for supervised learning,
to check if they are really correct or not.
That is called annotation.
Annotating the datasets.
It's a very important step
and it's very, very extensive.
The cleared, cleaned,
annotated datasets are solved
for high price tags.
In this case, we have it
for free times to Stack Overflow.
Now, it's a very balanced problem.
We have 2000 representation of
each category in our full dataset.
We will use similar pipelines.
We have 40,000 data points.
We have lots of
features more than the previous one.
In the previous one, it was 30,000,
20,000, 30,900 features.
These are the words,
these are the unique words,
but here there are too many, 180,000.
This problem is incredibly difficult.
40,000 times 180,000 is
the matrix size of x to be dealt with.
I'm using similar approaches.
However, in this case,
if I run a cross-validation approach,
it would go very slow.
So in this case,
my evaluation is simpler.
I'm using a test train
split so that it wouldn't,
it wouldn't run forever.
The results are here.
Again, logistic regression is very slow,
16 min for the split evaluation.
In order to list how the classifier
is working individually on each category.
I'm not using k-fold cross validation,
but using split 70 per cent training,
30 per cent testing given here.
You have to fix the random state.
Otherwise, every time you run this,
it will generate different results
because a seed would be
starting the pseudo-random function
from a different initial value.
So I'm sitting this 42 to keep
this notebook generating the same results
every time it's strong.
Well, dotnet, not that good performance.
Html, not that good.
Ios, not that good,
but Ruby on Rails, 95, Android 95.
Overall, it's thought that
this is a very difficult problem.
The highest performance and achieving is
linear SVC is much faster
than logistic regression always.
But for for comparison purposes,
we included all these
classifiers and these are
the detailed results for
our train test split.
Now, the TF-IDF vectorizer
generates a sparse matrix.
Most of the matrix operations won't work.
We have to convert it to, to dance.
But if you do a cross-validation like that,
you will be out of memory.
So this is a real-world problem.
It's a really big difficult problem.
People work on
months and months and months
on such problems.
Here, we demonstrated that it's doable.
If you know what you're doing,
you can do it very
accurately, very, very efficiently.
80, 1% is not bad.
Random performance,
achievement could be 1/20.
It's nothing, right?
1/20, it's only five per cent.
So compare
that five per cent random performance
to 80, 1% accuracy.
And this is without anything,
we haven't optimized
any NLP approach or word processing.
They're just using the TF-IDF vectorizer
directly from the library.
So many, many things can be done.
But if you trust my experience,
it would be difficult to
improve this performance to,
let's say, 90 per cent.
This is a difficult problem.
Maybe we can improve this to 85 per cent.
That's it.
Now why did linear
SVC we're much better than the rest.
The reason is this.
I have many, many features
compared to the data points.
That's why a decision boundary like this
works good because my PDF is not like this.
For the TF-IDF, it's
very localized in two-dimensions.
You wouldn't see a PDF like
this from the TF-IDF matrix,
which is the X matrix,
but you would see localize points.
Thus, a direct division of
the feature space would
work very, very nicely.
If you use word embeddings just for
the sake of completeness,
I'm mentioning this.
If you use word embeddings
in the instead of TFIDF,
linear SVC wouldn't work the best anymore,
because when we use word embeddings,
we convert this m2 a tighter,
more dense dimensions,
similar to principal component analysis,
my number of features would
drop from 80,000 to,
let's say 10,000 or 5,000 than SVC with
RBF kernel would work much
better because my m would be lower,
I would be more efficiently
using the feature space.
That's why it would work.