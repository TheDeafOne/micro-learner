Hello, I'm Dr. Ian Mccullough.
In this module, we are going to be
focused on online influence and persuasion.
This module is focused more on
social theory and some neuroscience.
There's a little bit of AI
that is focused in here.
You'll see that throughout the course,
I'm trying to have
a healthy mix of
the social theory that grounds the research
that we do with some of
the advances in AI and data science that
allows us to actually empirically
support those theories or reject them,
and to work with data and
actually produce something of interest.
And I think both are important for developing
your ability as a researcher
and as a scientist in this space.
So many people just do
what's available with data,
even if it makes no theoretical sense.
When you just start looking and
seeing what does the data tell me,
you're often
shortcutting the scientific process.
The scientific method should
involve observing the world around you,
then forming a hypothesis.
Only then do you collect data,
make analysis, and draw conclusions.
When people are just looking
at data and drawing conclusions,
there's a high likelihood
of spurious correlation.
You're highly likely to just find things
that that may not really
be accurate. It's a bias.
We also then tend to
add this arrogance where we
believe that because we're
using data and numbers,
it's inherently better than
people's opinions or lived experiences.
I would argue that all of
those methods lived experience
exploratory data.
All of those things are good
for exploring the world
around you to generate the hypothesis.
But you have to do that important step
of understanding the hypothesis,
then collect the data,
because that's going to
allow you to be
much more objective in confirming
or denying what you've seen and
mitigate or regard against
the risk of spurious correlation.
Looking at the theories
and the research that others have
done is a very important step
in informing those hypotheses.
And making sure that the
effort and the work we're going to
put forward in a project
is likely to be successful.
Our objectives for this module are to
explain the counter intuitive nature
of social media influence.
This is really important because a lot of
people just assume that because
things are stated online,
there's some inherent risk
or that people's minds
are being changed or
society is falling apart.
There's a interesting
counter intuitive nature
about influence in general,
and we're going to
explore that in this module.
Another objective is to
describe common theories of
influence and persuasion and
how they're moderated on line.
There's two important pieces to that.
One is understanding how from
a social psychology and
cognitive perspective people are influenced.
And then understanding what aspects of
the online environment make
that different or the same.
Then we're going to talk a
little bit about how
platforms manipulate those behaviors,
those features, and
how recommender systems work.
A few years ago we went through Covid.
Now I'm
also faculty in the School of Public Health.
And if you told me in 2019 that within
a few months the entire world
was going to wear masks and all,
go get vaccinated, all in
support of a major health pandemic.
Myself and everybody else in
public health would have thought,
you're absolutely crazy.
It's amazing the way the world responded
and came together to respond to this disease.
But there was a ton of
misinformation that was also being spread,
and many of you lived through that.
And I'm not going to delve
into that particular issue because
I think it's still
a very polarizing issue in the United States.
It became a highly partisan issue and it
became almost as polarized by
the politics that you're hailing from,
as much as it was anything about
the actual disease itself.
I use this as a point to say that
we have all had some experience
with miss or disinformation
and we've all have different opinions on it.
I think Covid. If you
think through your experiences,
through the Covid, it's
not exactly clear or easy to spot.
What's
truthful information
or what's disinformation.
I just give you
two examples here and I'm not even going to
state which one is the disinformation.
Either them or disinformation or true.
I'll leave that for discussion later.
Let's just talk about
some definitions before we
get deeper into this.
The first definition is
the idea of misinformation.
Misinformation, also known as
fake news, is incorrect information.
It's just wrong, it's a falsehood.
There is also what's
less discussed is malformation.
Malformation, it's bad.
It's not exactly the opinion or view
that you want to espouse, but it's true.
There can be truthful information that is not
good is more than just misinformation.
They're not synonyms. Disinformation has
this additional component to
it that not only is it false,
it's delivered with the intent to mislead,
it's attempting to change opinion.
There is two concepts
here that are not necessarily correlated.
Propaganda is information that is
presented in a biased way
with the intent to persuade.
The point here is that can either be
truthful information or false information.
When we look at this, there's
an example I like to use,
South Park right here.
There's a lot of times that there is
incorrect information trade on
a parody show or something like that,
and the intent arguably
is not to persuade or change your opinion.
The intent is to entertain.
It doesn't necessarily fall
in the category of propaganda,
although, depending upon the show's creators.
And that's an arguable statement, right?
Some videos or some entertainment
is delivered with the intent to persuade.
If we look, for example,
at Russia's
preparation before the invasion of
Crimea and the annexation of
Crimea or before their invasion of Ukraine,
they flooded the Ukrainian or
previously Crimean information environment
with
tons of entertaining shows
like soap operas and music,
and tons of things to get
the people interested in
Russian language, Russian culture.
So that when they invaded
large portions of the population,
we're quite happy to be part of Russia.
And not necessarily wanting to resist
entertainment can be used
as a powerful tool in propaganda.
But my point is that there is
examples of fake news
or incorrect information,
misinformation, that is not
delivered with the intent to mislead.
There is also truthful information
that is presented to persuade.
One of the classic examples is if you look
at one of the US elections, 2016,
Russia released tons of negative mal,
information about
presidential candidate Hillary Clinton,
which affected people's opinions
of that candidate and influenced
the outcomes of US elections.
And that was very deliberate.
Now the trick was
that Russia did not use
any fake news or misinformation.
Thus they were just
educating the US population.
It was very difficult for
the US to understand how to respond.
They can't call that the election is
false or not valid.
Because people were educated.
They can't un, educate the people
and hide information that they already know.
Sometimes mal, information is
a much more powerful tool in
propaganda than misinformation is.
And then the argument was that, well,
why didn't Russia say
a bunch of negative information
against Donald Trump? Was that their job?
I did. Russia have to do that.
It's very difficult to understand how we
should respond to those issues.
You know, the other issue
that I think has been mischaracterized,
if you actually look at the timing
of when that was released,
it was actually in the Democratic primaries,
and so I personally
believe that Russia's intent
was to promote
Bernie Sanders over Hillary Clinton.
Arguably,
if Bernie Sanders had won the primary,
he probably would have beat
Donald Trump, according to the polls,
because America was very
prime for a populist candidate.
That was not establishment
somebody kind of knew,
and so Bernie Sanders
was that for the Democrats.
And so I think Russia felt that that was
the best time to get to influence
a US president that was much more closely
aligned with political values
that agreed with Russia.
And I think it backfired on them.
So I think the traction
in social media was delayed.
It didn't pick up quick enough and it was
post DNC primaries that
all of a sudden the negative information
about Hillary Clinton came out,
which then supported Donald Trump.
And there's a paper later in the course
where we'll look at Dormant,
bought a way of platform
manipulation that Russia used in
the 2018 midterm elections
to support the other.
Other candidates, other party.
As we look at propaganda
with these definitions, right,
We can look at different versions
of this and see that it's a
little more complex than
just fake news or true news, right?
There is satire, parody we just discussed.
There's no intention to harm,
but it certainly can fool people,
can influence people,
there is false connection.
This is a type of
along the spectrum of propaganda
where the headline or
the caption for visuals
don't support the content.
You take a picture in
one content and then
you present it in another.
There is misleading content.
This is where you take truthful information,
but you're framing it and presenting it in
a way to persuade
people or to be
biased in the way
you're presenting the information.
There is actual false content.
So these are where you
now get into the realm of
fake news and you just have straight up lies.
There is imposture content
where you take like a genuine source,
you're doing a deep fake of an individual.
You're impersonating somebody or
you're maybe even just putting
a false caption to
a real person saying that they said it.
That's imposture content.
Then there's manipulated content.
That's where you go in and you Dr.
a photo or you go into
Photoshop or something like that,
add things or manipulate the images and then
there is 100% false
and new fabricated content,
synthetically generated
to design, to deceive, right?
This is just showing that there's
a spectrum of disinformation
and it's not cleanly
defined into certain blocks.
That's part of what makes it difficult
from a research perspective because
how do you actually
bound the experimental conditions to collect
empirical evidence and like
test hypotheses about how this is working.
We'll look at a little bit more of this
as we go through this module.
In this lecture, we've talked
about several definitions, right?
We've talked about misinformation.
False information that
exists in the environment.
Misperceptions is false beliefs,
we didn't talk about that before.
But a false belief is where
a person is believing
something that is not true.
Deception is the intentional effort
to cause other people
to develop those misperceptions.
Propaganda, again, is information
presented in a biased way
to affect the beliefs of others then ate.
Let's define attitude.
Attitude is an affinity towards
certain stimulus that affects
neural processing the information.
So it's not a belief necessarily, right?
A belief, hey, I
believe smoking is going to give me
cancer in X number of years, right?
But my attitude towards smoking is, hey,
am I going to be more likely to believe
positive messages about smoking
or negative messages about smoking?
Am I going to be more likely to believe that
smoking is going to help me with
my anxiety and weight control?
Or more likely to believe that it's
a health hazard and it's gross, right?
That's where the attitude is.
So I want to offer three observations.
One, not all exposure to
misinformation causes a misperception, right?
You can see stuff that's clearly
wrong and rejected out right.
A lot of times people
get worried that because there's
misinformation on
the Internet that it's all of
a sudden changing people's views
and perceptions and causing problems.
It's not exactly, that's that clear, right?
It's a little more complex than that.
Not all misperceptions
are caused by misinformation.
A lot of times you can believe
wrong things by
viewing true information, right.
A person that views
truthful information
that Russia presents about
Hillary Clinton might lead them to believe
things about that candidate that are
completely unfounded and completely untrue.
And we'll talk about an example of that that
occurred in a pizza shop in Washington, DC.
People can also correct
misinformation and misperception,
but still have negative attitudes
towards future information.
One of the dangers that happens
when are the victims
of misinformation and misperception.
You can correct the record,
but it doesn't correct
the underlying emotional attitude that people
have encoded in
their brains towards that information.
And then it makes them more susceptible
to propaganda in the future.
I'll give you some examples.
There's a study that was done
that showed that 68% of
America believe that China
owns more than half the US debt,
right? That is true, right?
But the misperception then
that people have from
that factual information is that many
think that if the US doesn't pay its debt,
China can come in and
repossess parts of the US.
Right, well, that's not true, but
there is a belief
anyway that politicians do
not want to correct the misperception.
Because if people actually believe
that China didn't have
the authority to do that,
then they say, well,
who cares about the national debt?
And then that leads to
poor fiscal spending, right?
Because the economy or
economics of the country are
far more complicated than
most voters can understand.
And there is a lot of
misperceptions that exist based on true data,
true information, and nobody's
interested in correcting it right.
Misperceptions can be fact based.
The last statement that
I made previously about
negative attitudes persisting defined
as this concept called a belief echo.
With belief echoes, you might get exposure to
misinformation that causes a change in
your attitude and it
persists even after you
don't believe the misinformation.
A classic example, we see
this all the time on social media,
that there is a celebrity
accused of some heinous crime.
The celebrity goes through
some court procedure and is found not guilty.
Now, keep in mind, a lot
of these court proceedings are closed,
or they're very long,
and nobody really follows
the entirety of the court case,
regardless of the due process.
People now dislike the celebrity,
so you might be looking at this and saying,
well, yeah,
but the celebrity is guilty, right?
Like 0, J really did do it, right?
The issue is that if
somebody is accused of the crime,
regardless of whatever objective
legal process is done,
it doesn't change the
negative attitudes that have been
created by being exposed to
the misinformation in the first place.
This plays into inoculation theory.
Inoculation is the idea that if
we equip people with truthful information,
we prep them in a certain way.
That there's something we can do
to the general public that
inoculates them from believing
misinformation or fake news
in the first place.
And the general idea of inoculation,
it comes from vaccines, right?
Where if we state a positive message,
right, Like we state the real message
that we're trying to do, right?
And political party X is great
because of their wonderful plan for,
I don't know, America positive message.
And then we state a weak counter argument.
We take our opposing view and we
take the weakest form of the argument.
Right? And we introduce that,
then we explain why that's wrong,
and then we echo the positive message.
That is the typical approach for inoculation.
The idea is just like if we
inject you with a weak form of the virus,
you build up the antibodies to reject it.
That's the idea of inoculation.
But here's the problem, stating
any counter argument may
create the belief echo.
Even stating that we counter argument,
you may be introducing something,
especially if it's novel,
especially if people haven't heard it before,
or especially if they're
predisposed to that in the first place.
They can create a belief echo.
It's much like having
a reaction to a vaccine.
The general view that I
take is it's better to
inoculate against the source.
What does that look like?
Let's take some misinformation.
And I'm stating it, so hopefully I am
not manipulating you
in doing this inadvertently,
but hopefully you know that this is
misinformation up front, right?
Sugary soda boosts the immune system.
It does not. I'm just saying that
I guess I'm giving you a belief echo.
Right? Let's say that's
the misinformation that we are
trying to inoculate against.
Counter message one, this is an example.
You may hear that sugary
soda boosts the immune system.
This is not true and research shows there's
no evidence for this. Soda is bad for you.
Now I'd like to just
pause the video for a second.
Write down on some notes
what might be wrong with that message.
What might be a better way to craft it?
Take a moment to try and re,
craft that message with
the information I just told you about,
inoculation theory and
the risk of belief echoes,
and see if you can come
up with a better message.
Assuming you've had a chance to
pause and do that exercise,
I'm going to now invite you to continue.
And let's look at what I did, right?
So counter message number two.
You may hear the sugar lobby try
to spread misinformation about sugar.
They just want to make money and we'll
mislead sugary soda is bad for you.
I've never stated the misinformation.
What I have done is
I have attacked the source, right?
I've said the sugar lobby.
I don't even know that's a thing.
But like these people, right?
The more vague that the opponent is, right?
The more abstract it is,
the more people will connect dots and it's.
It's more effective against
a wide variety of potential sources.
I then give a plausible reason
why somebody is trying to do that, right?
They just want to make
money and will mislead you.
Right now, I've given a reason for
you to believe that statement.
And then I introduce the correct view, right?
Sugary soda is bad for you.
That is a way that you craft
a message to inoculate people
against the source, not the content.
You will notice that since
this research was published in about
the mid 20 teens around you,
mid part of the 2010,
I don't know how we call that decade,
you'll see politics
has changed in their messaging.
It is less about debating issues and
it's more about attacking
the source and the character of candidates.
If they can get you to believe
that a candidate is bad,
they can actually create belief echoes
against the candidate or
the source even if they're not true.
And we'll talk a little bit about
that going forward.
Interest on social media
also affects what people
look at and what they believe.
What you're seeing here is
a study that was done in 2016.
And these are five fake news stories, right?
They're all false. You can
look at the slides or read them if you want.
The point is that
the first question they asked, hey,
have you seen or heard about
the following story in the past few weeks?
What you see is, I don't,
roughly ten to 20% of the people
had seen the stories, most had not.
Then they ask people,
well, what is your
perception of the accuracy?
And you'll see that there is high accuracy.
There's a high perception of
accuracy amongst the people that viewed it.
We might only have one in
five people seeing the ad.
But of those one in five people
that are seeing the ad,
right, like 4.5 of those people believe it.
That's telling you that
the people that are actually looking at
the misinformation or
the disinformation are much more
likely to believe in it than people that
are not then the general population.
When we look at information diets like,
what you're seeing here is
a spectrum of news stories.
Right? On the left what
you're seeing is, you know,
red, our conservatives blue or
liberals Gray is neutral, right?
We can look at the diet of a normal person.
Are going to be equal in their viewing
of liberal conservative and neutral stories.
But when you actually then look at
the stories that are being viewed by
people that I identify with as
conservative or as liberal, right?
You'll see that their diets
are much more segregated.
So there is a health like
the largest group probably is in the middle,
but you'll see that there's that large
red conservative spike on the right.
That's the right wing,
heavily conservative people.
You'll see on the left with liberal content,
there are actually two spikes.
There is left wing and then there's
very left wing that are in two modal spikes,
but there's not as much of a valley, right?
So it's a little bit
more of a smooth spectrum.
Moving left, right, we find
that we notice that
people have certain ideological beliefs.
The more extreme
those ideological beliefs are,
it affects the content that they go to.
When they go to the content,
they're much more likely
to believe disinformation,
consistent with the
ideological views that they
have is what is
increasing the polarization
or a sense of polarization.
When you look at sources of disinformation,
what you're seeing on the top bar there,
you see the news sites.
Most people get
their news sources from direct browsing.
There's other links.
Then there's search engines.
This is going to be like
when you type something into Google,
it's going to recommend some stories to you,
right? That's the search engine.
If I wasn't clear on the direct messaging,
that's where I'm going to go to CNN,
I'm going to go to Fox News, I'm going to go
to Wall Street Journal,
right, Or something like that.
And then you see social media making up
about 10% when you look at
a survey that Alt and
Ginko did on fake news, right?
And where fake news exists,
what you see is fake news is far
more prevalent on social media,
this is in 2017 than anywhere else.
Whereas the proportions of
the direct browsing search engine and
other links is about
the same proportions. Right?
We see that social media
is far more involved in the whole fake news,
which is one of the reasons
why in updating the courts.
Right. I've added a whole lecture
here on influence persuasion,
disinformation, and we expanded those topics.
In summary here, fake news is more likely to
be viewed and believed by those
with a skewed information diet.
And the polarization comes
first that affects what
news sources people go to.
Then that affects the
continuation of those views.
This has been a short lecture introducing
you to influence and persuasion.
I look forward to talking to you soon.

Hello,
I'm Dr. Ian Mccullough and we're going to go
deeper into influence and persuasion.
And we're going to be looking
at boomerang effects,
that's
the counterintuitive nature of influence.
And we're going to be
looking at rumor correction.
And what actually happens
from empirical data when
people try to correct
rumors or misinformation online.
In order to understand
counter intuitive nature of influence,
we need to begin with social judgment theory.
Social judgment theory is
a fairly old theory.
It's I think initially proposed in the '50s,
and it really is focused on
attitudes and attitudinal beliefs.
Attitudes and beliefs. So I'm
going to use an illustrative example.
Let's take an absurd topic
like the death penalty.
Right? I've created
a spectrum of potential views,
Some are absurd, some are probably
what you believe somewhere in the middle.
What should we do with
somebody convicted of murder?
And this is everything from, hey,
should we give them a ward slap on the wrist,
or should we not
just give them the death penalty,
but death by torture and horrible outcomes.
Right, so when you look at the range of
attitudes that a person can have
towards our attitudinal beliefs
a person can have, right?
We can look at a person
and we can categorize their view
of these positions in
terms of a latitude of acceptance,
rejection, and non commitment.
The latitude of acceptance
is the range of views
that a person thinks are very
reasonable and a normal person should have.
This person here believes
that life without parole or
the death penalty are
acceptable attitudes a person
can have towards the death penalty.
The latitude of non commitment is
one that they don't
think is quite reasonable,
but they can understand why
somebody would have that view.
This person understands why
somebody would believe in
giving somebody parole later.
But they think that anybody that gets like
a defined prison sentence of 20 years
or less is absurd, latitude of rejection.
But they also view that death
by torture is excessive.
And latitude of rejection.
Sometimes that latitude of
non commitment nonexistent,
like you see 8-9 here.
Other times it can be a little bit bigger.
There is work on how do
you actually widen the,
somebody's latitude of noncommitment
on issues so that they can
engage in discourse and
have better, more productive conversations.
Well, here's another person. This person
does not believe in the death penalty.
This person believes that life with
the possibility of parole
is the acceptable view.
And you'll see that they understand
why somebody would believe
in life without parole,
but they reject the death penalty.
They also understand why somebody would
believe in a fixed prison sentence.
But they think a fine and
no prison time at all is absurd.
So how might these two people
argue or try and persuade each other?
Right?
I want you to
take a moment to think about that.
Let's say that the person on
the left right is trying to
convince the person on the left
is the person that believes
in the death penalty,
is trying to convince the person
on the right that
does not believe in the death penalty
that the death penalty is Okay.
So I want you to pause for a second
and just write down a note real quick.
What would you do if you
believed in the death penalty?
What type of argument would you mount against
this other person that does
not believe in the death penalty?
To convince them, it's
really important to take
a moment to jot some of those ideas down.
I'm assuming you've had time to do that.
Pause the video and do that,
and now we're going to resume.
Most people are going to say,
let me put really
strong arguments for the death penalty.
Let's talk about how horrible the person was
and they don't deserve
anything. Eye for an eye.
They're going to present
really strong arguments, right,
as to why we should
go beyond death and death by torture, right?
They shoot beyond the target.
What happens cognitively,
is it lands in the latitude of rejection.
And it has the effect of actually
pushing their anchor position the other way
so that they become more lenient
instead of favoring the death penalty.
This is social judgment theory.
It is a very robust theory initially proposed
in the '50s because
they observed it in people.
Countless experiments have been done on that,
and they've basically demonstrated this
is the boomerang effect
that occurs when people are in argument.
What happens when we
try and correct misinformation?
And how might social judgment
theory help us understand this?
I'm going to use an example that
Adam Bernski highlighted from
2017. He did a study.
On the argument that
President Obama was not a US citizen.
You may not remember this, but
during his first term as President,
there was an argument that nobody had
seen President Obama's birth certificate
and he wasn't a US citizen,
therefore, he was not
a legitimate presidential candidate
and he was not
the rightful President of the United States.
So at the time, people were like,
if my man would just
drop his birth certificate,
this argument would be done
and everybody would know what the truth is.
Well, he didn't at first, and people
criticized him quite heavily.
Well, in April of 2011,
he released the birth certificate.
Adam had polling data on what
people's attitudes were before
the release of the birth certificates.
You see that top table.
Before the release of the birth certificate
in April 2011,
55% of Americans thought
President Obama was a US citizens.
15% thought he wasn't.
In a large number of thought he was.
They were unsure as to what
his citizenship status
is immediately
after the release of the birth certificate.
Like you'd expect more people
believe that he's a citizen.
Many of the not sure people entered
the camp of believing that he was a citizen.
And there was a little bit
of a decrease in
the people that thought he was not.
What I want to draw your attention to
is look what happens a
little over a year after
the release of
the birth certificate when they polled.
Again, not only is
the same number of people
believing he's a US.
Citizen, there's actually more people
that believe he's not a US.
Citizen. When you look at the numbers here,
among Republicans only, right,
You'll see that far fewer of them
initially believed that he was a citizen.
More of them thought he was not
after his release of the birth certificate.
Those numbers are significantly worse, right?
Way more people believe he's not a US.
Citizen in the Republican camp.
Why? Well, people counter argue,
if they get exposed
to information they don't believe in,
especially when it lands into
their latitude of rejection,
they have that boomerang effect and
they get practiced at
coming up with reasons to discount
the factual information
that's presented to them.
This is common in
almost all examples of
rumor correction or
misinformation correction.
You see a short run,
two weeks to a month change
in behavior as you would
expect for correcting the record.
But after that period of time,
not only do you go back to the same levels
as before the misinformation was corrected,
but you get far worse.
We're not really good at
understanding our cognition about this,
right?
What I'm showing you here
is a study on smoking cessation.
And I'll tie it back in a moment.
There were three different ads, right?
For ads to call
1800 quit now for smoking cessation.
The behavior that they wanted to create,
somebody's going to call the 1800 number
when they asked people to
report on the ads, right?
Everybody liked add B,
they thought A was okay
and C was a bit of a stinker.
You can see that this is rated
on a scale of zero to ten.
Now, you haven't seen
the ads, I apologize for that.
I can't show them for a certain
copyright reasons, which is annoying.
Add A and B are what
you'd expect people dealing
with smoking and quitting,
and acting all desperate and then saying,
hey, call the number A C was absurd, right?
It was a little thumb
with a smiley face on it,
and the thumb was trying to
figure out how to quit smoking.
It was very cartoonish
and everybody thought that was not as good.
But Emily, what she did is she put people,
as they're viewing these ads into
a MRI machine where she could measure
activity in a certain brain region
called
the medial prefrontal cortex that exists
right above your eyes
or the middle of your forehead.
What she found was that there was
a different activity response across the ads.
In the ads at C had
a lot higher activation than at
a very different than
what the self report rankings are.
But what was interesting is
when they actually looked at
these ads were launched at
different times amongst the same population.
What they saw was that the call volume
of people that called
a while the ad was running,
tracked almost perfectly with
the neural response to ads
and not at all with
the self reported rankings.
Conclusion out of this
is that we are not really
good at being conscious
of how our attitudes
and beliefs are changing,
how our behavior is changing,
or why we're adopting certain behaviors.
But our brains are
a much better indicator of what's going on.
Neuroscience provides a very powerful way
for us to understand influence and
persuasion and be more accurate at
assessing what's going on.
How does this work?
I'm going to introduce a model of
neurocognitive influence
model that I developed
with Matt Lieberman at
UCL and Emily Fock at U Penn.
The idea here is that
On the right, you'll see that there's
that box of behavior change.
That's the output, right?
We can see behavior change,
according to Emily Fox paper
and several other ones that have been
done since then is highly correlated,
that's what the solid line is,
with activation in
the medial prefrontal cortex,
with self integration, right?
There's also an area called the
PCC that also is correlated with that.
And I'm showing you a picture on
the left of where those systems are.
We know that if there's activation there,
it's likely behavior change.
Whether or not we can report on
that with self report is questionable.
We also know that when
we're exposed to information that
we don't like or we disagree with,
counter arguing occurs right,
lateral prefrontal cortex.
That's the area in yellow,
orange you see there.
When that area is active,
it's negatively correlated with activation in
the medial prefrontal cortex and it
disrupts your ability
to affect behavior change.
We know that when
you invoke rhetorical persuasion.
So that is Aristotle's
ethos pathos logos, Right?
I'm either going to do an emotional appeal,
I'm going to do
a logical appeal with numbers,
or I'm going to do
some credibility key person
opinion leader type appeal.
Right? Like when we try and use rhetoric.
If the rhetoric is
consistent with what we already believe,
it increases activation in
the medio pre feral cortex
and results in behavior change.
But if it's information
we dislike and we
don't like hearing about it,
it actually creates activation in
another part of your brain which
shuts down your ability to
listen to and understand new information.
In fact, it gets practiced at coming up with
new and other information that
are much more likely to be received.
And this is what we believe
causes that mechanism of boomerang.
Well, in cognitive and social psychology,
there are three known ways
to disrupt counter arguing.
We know that that is affirmation,
distraction, and narrative immersion.
Also, musical immersion can do that as well.
What neuroscience studies have
shown is that when you do affirmation,
affirmation affects two key areas.
The ventral stratum and
the orbital frontal cortex,
which is where self affirmation occurs.
Social media actually invokes this too.
We'll talk about it a little bit.
When you have that reward circuit
activated in your brain
and the release of dopamine,
it shuts down counter
arguing as a mechanism allowing
the self integration through
the medial prefrontal cortex
to be much more strong.
We know that when the
reward circuit is active,
it's negatively correlated with
counter arguing regions of the brain and
positively correlated
with the self
integration regions of the brain.
Similarly, when people are
immersed in a story,
we can see activation
of that through empathy in
the dorsal medial prefrontal cortex
and the temporal parietal junction.
When people are immersed in the story,
it also shuts down
the counter arguing portion of
the brain and is positively
correlated with self integration.
As a result, when we think about influence,
people are already
predisposed to counter argue.
The whole idea of inoculation is to
prime that area of
the brain to counter argue.
But if a person is able to come with
a message that is high in self affirmation,
high in story appeal
and engaging story in a narrative,
the narrative transport and
the positive affirmation shuts
down that and it gets
access to that area of
brain changes of opinions are going to occur.
I've done a lot of this research myself.
One of the areas of my research interest
is social neuroscience.
These are some experiments
that I did in Amman,
Jordan over a series of experiments.
The first one I did as Johns Hopkins faculty,
and then when Johns Hopkins was a little
bit concerned about the research
I was doing from a risk perspective,
I did it through a small business.
I have Aero analytics.
I've assessed the effectiveness of
public health ads in Jordan and Egypt.
I've assessed sectarianism in Iraq among
Sunni and Shia Iraqis,
and I've assessed
the effectiveness of tobacco ads.
I'm currently working on
HIV prevention and further tobacco cessation.
And you can talk
to me in the synchronous chat if you like.
But I've also started a nonprofit,
the Brain Rights Foundation,
to provide AI and neuroscience research
to help front line treatment centers
address things like substance abuse,
mood disorders, PTSD,
and other brain related pathologies.
Some of the findings that we
had in our research
was that the medial
prefrontal cortex activity
I was talking about,
right, predicts advertisement effectiveness
over and above perceived effectiveness.
What I was able to measure with
a tool we developed
called functional near infrared spectroscopy.
It's not an MRI machine.
It's a much more lightweight,
easier system to deploy.
You saw a picture of it
in the previous slide.
It has much less spatial detail.
It is also not as temporally
accurate because it's not
measuring electrical properties of the brain,
it's measuring blood
resupplying neurotransmitter.
So there's a little bit of a delay,
but it is smaller, lightweight,
and much easier to take to
the field or different settings.
What we found was not
direct measurement of the prefer,
but we measured that dorsal media prefer,
which is really saying, hey,
are people bonding with the ad, right?
Not the expected region.
We also though, look
at an area of the brain where
we think that identification
and empathy is occurring.
So people are identifying
with the characters in the story,
and that is more of
what we're actually measuring.
In my research, I did look at counter
arguing and counter attitudinal beliefs
in terms of how effective was the message.
What we found was that
there was this negative correlation,
you see negative 0.17 correlation,
statistically significant between
that medial prefrontal cortex area
around the frontal poles of the brain
and the counter arguing region.
Also found that the more subjects
reported intention to do the behavior,
the, the negative correlation existed.
We see that the stronger
the negative correlation
between those two regions,
the less likely the subject
is to actually engage in the behavior.
Another view that I did for a pilot for
the Food and Drug Administration
was looking at a variety
of different tobacco ads.
You see these are ten different tobacco ads.
We exposed a group of adolescents,
these were high school students,
to various ads.
We measured their neural response.
What I'm doing here is I'm
measuring asymmetric response in
the frontal poles to measure
either motivation and engagement
or avoidance and withdrawal.
Then we're measuring
right lateral prefrontal cortex activity
to see is there
message resistance or acceptance.
What I observe here, and you can look
at these ads yourself if you want to pause,
is in the upper right here,
you'll see a series of ads from
one particular tobacco
vendor which is showing
nature and planting trees and active stuff.
Those were appealing, they're in
the upper end of the graph here.
But there was a little bit of resistance
about whether people were
believing that this company was
really doing good things for the environment.
If you look at the bottom here,
which I think is interesting is
more is better, You see that ad.
That is a ad where
the tobacco company is just saying,
we have the most nicotine on
the market, we're going to kill you.
What we found is merchandising
was super high for that.
But there's actually an avoidance withdrawal.
And the tobacco sales for
the actual tobacco was
less than you would expect.
You almost see the people
here in the audience of high school students.
It's almost like, I think
they're like posers, right?
They want to show that
they're daring and that they're high risk.
But they don't actually want to
do that negative behavior.
What was really motivating and
accepted as you see in
the upper center left, right?
This is a tobacco ad
that's talking about organic tobacco.
And does the presence of
Eco friendly ads increase
motivation or engagement to the ad?
We find that ones that are green in
color tend to be more
engaging than ones that are yellow or red.
This actually
launched a whole study I did for
the FDA on eco friendly tobacco ads.
We study that data in another class I
teach in the systems engineering department.
The top ad, however, was
one that's showing engagement.
So friends and fun.
And that thing becomes
what we consider the top ad.
It's engaging, motivating.
It's widely accepted.
That's a way of using
neuroscience to judge the
effectiveness of different ads.
Then we can see that
those ads, in other studies,
there's
a well established field of neuromarketing
which shows that the
more appealing those ads are,
the more effective they are in generating
sales of that product or views or attention.
But our conclusion here is that
misinformation is sticky, right?
When you are exposed to
misinformation and
you hadn't thought about it before,
that becomes your first baseline.
Now all new information is viewed
within the lens, that initial view.
When you try and fact correction,
it fades over time because
of things like belief echoes,
because of the boomerang effect.
Because of getting practice,
that counter arguing attempts
to really deal with
misinformation has to guard.
We properly
inoculated against sources of misinformation.
Do people believe what they see on
social media is their initial view that like,
I can't believe anything
I get on social media.
I got to go to a reputable source
when they're exposed to it.
Are we working on widening people's latitude
of acceptance so that they can have
discussions that are meaningful?
Or are we just jumping
to extreme arguments that actually
create the boomerang effect and
widen the polarization gap between us.
The key thing we have to do in this is avoid
the boomerang because once that happens,
it doesn't matter the factual information,
it's not going to help, right?
You know, I'm not sure
I'm going to keep doing
this semester after semester.
But for a number of
semesters in teaching this course,
I would ask the discussion question,
what should a political candidate do when
their opponent broadcasts lies
about them that are not true?
Right? And deliberate mis information.
How should the politician respond?
Well,
despite this discussion that we've just had,
despite looking at the science,
I find that well over 90% of
the students always say that
the politician should
stand up for themselves and
correct the record why
we saw that with Obama.
That actually went far worse with
his opponents and didn't
make a single bit of difference.
It actually made his situation worse.
Just our gut tells us
that if somebody says something,
they're wrong.
We need to correct it.
We need to tell the truth.
The science, the empirical evidence just
suggests that that's absolutely not
true. What do you do?
Well, we need to reframe the situation,
and we'll talk a little bit more about that.
And later in the module.
I'm Dr. Ian Mccullough
and I hope you've enjoyed
this lecture on the
boomerang effect and rumor correction.

Hello, I'm Dr. Mccullough.
In this lecture, we're going to go
deeper into the area of social neuroscience.
I know we've talked a little bit
about that in the previous lecture.
We're just going to go more in
depth and this is
a topic that I'm really fascinated
about and I hope you're
going to like it as well.
I think the most foundational theory in
social neuroscience is what
we call the James Lange Theory.
William James is considered
the father of psychology.
He offered the first psychology course,
I believe, in the late 1800s.
He's also the guy that came up with
the concept of system
one and system two thinking,
which we'll talk about shortly.
But he was interested in understanding
the idea about habits conscious attention.
The James Lange theory is very fascinating.
He says that the way that
our brain responds to
events is that there's an event.
Right here, you're seeing a snake.
The next thing that happens is the event.
The perception of the snake
first creates a physiological response.
Elevated heart rate, sweating,
maybe a release of adrenaline, right?
There's a physiological response first.
We then interpret,
or don't interpret that response,
but it's the physiological response
that creates the emotion of fear.
Then we interpret
that physiological emotional response,
however,
our brain rationalizes it
or makes sense of it.
But that's really fascinating
because a lot of
times think that we have the emotion first,
then we have the physiological response,
but it's actually the other way around.
This has been supported
with neural imaging studies
to see that sequence of events.
The question then becomes, well,
why do we have the physiological
response in the first place?
Well, this occurs in
our deep brain where we
don't have much rational thought, right?
It's in the deeper part of the brain.
What ends up happening is this
is almost animal instinct, right?
Where we develop a conditioned response.
The first time you see a snake,
you don't know what it is.
But as you learn what danger is,
as you're growing up, these cues
get encoded into your deep brain.
And you become conditioned to have
a certain response to stimuli.
That's why it might
be pain if you touch a hot stove,
but if you've had
repeated experience with an animal, right?
Like a little dog that's been
aggressive and mean you might
get conditioned in a response to be fearful.
Well, what's getting conditioned is
a physiological response to the event that
then is conditioned to
an emotional response and
then our brain starts making sense of it.
That's why it's very difficult to
overcome some of these factors,
especially if there's been severe
trauma in people that
has encoded some of
these physiological responses to events.
James also came up
with the idea of system one and
system two thinking it's not
really left brain, right brain.
But that was just the cool picture
that I had for the slide.
But we have this one side of
our brain that is very rational deliberative.
It is where we are weighing
alternatives and objective decisions.
The other part of
our brain is more automatic.
It's response to external stimuli.
It's like habitual when
we are measuring people in a survey
or something and asking them to
self report on
their behavior or on
what product they're going to
buy or what have you.
What we find is that
we're not really good at
rationalizing our own decision.
One of my favorite neuroscience studies
is the Coca Cola study.
If you've heard of
the Coke Pepsi challenge, right?
That's where you give
a consumer coke and you give them
Pepsi and they have
to decide which one is better.
In a blind study, when they don't
know what the product is,
people choose Pepsi on average.
Why do they choose Pepsi?
Well, Pepsi has a higher sugar content,
it has a greater dopamine release,
and it is more chemically
addictive than Coca Cola.
But if you show people the brand name,
most people will choose Coca Cola over Pepsi.
While the argument is that there is
much higher branding associated with it.
The brand of Coca Cola has been tied over
a century with things
like Santa Claus or Cuddle Polar bears,
or there's Coca Cola commercials.
I remember the one that says.
We're going to teach
the world to sing, right?
They just appeal to good old values.
Comfort, happy memories.
They try and invoke an emotional response.
In the neuroscience study,
somebody actually put people
into an MRI machine.
They have this very, very long straw,
so they could do the taste test.
When they start tasting the Pepsi,
you can see the greater dopamine activation
in Pepsi versus Coke.
Then when they start telling
them that you're drinking Pepsi,
you actually then see the activation
in the cortical areas of the brain,
which are prefrontal cortex,
which is more associated with
decision making, get activated.
And you actually see
the neural pathways of people changing
their mind and regulating
the reaction of dopamine.
It's just really powerful
how some of these studies can
really illuminate how the brain
responds to content.
It also shows the power in marketing.
It says that your best marketing approach is
not to present objective, rational arguments.
Because most people aren't going to take
the time or the energy
to evaluate those arguments.
If you can actually target
the emotional response in people and
develop feelings of
happiness and positive emotion,
that is going to be much more
correlated with successful sales.
In a neuromarketing perspective,
how does this work?
Well, I talked about the dopamine response.
So the way the dopamine occurs, right,
is dopamine is primarily,
it's rec, in two areas, right?
The ventral tegmental area
and the Stanchi Niagara.
The ventral tegmental area is most of it.
That's that little green dot that you see.
You see that brainstem, right?
The closer you get the brain stem,
the more primal it is.
They talk about the cortex
being an evolved thing form.
What we know is
humans have one of the largest
surface areas of the cerebral cortex.
That's why it's all folded
together as you see there, right?
If you actually unfolded it,
it's a large cerebral cortex.
The size of the cerebral
cortex, The surface area,
the cerebral cortex is highly correlated
with the size of primary
social group and primates.
Some people call the inner brain the primal
brain and the cortical
regions, the evolved brain.
We can also think of the inner brain system.
One, thinking right, these are
the emotional response system.
Two is the thinking brain, right?
Where we're thinking through that.
What ends up happening is dopamine
is released in that primal brain.
And then it has two pathways.
One heads towards the cortical pathways.
This affects like the
motor cortex for movement,
which is a problem in Parkinson's patients,
they have a dopamine deficiency.
But it also activates
areas of the brain that's going to be
affecting decision
making and regulation of decisions.
The other part, it goes to
the Limbic System which is
the reward circuit, right,
Which is what we typically think of
a dopamine which is
encoding some of the operate conditioning
for our behaviors.
It's a key neural hormone for motivation.
It's motivating us to act.
It's motivating us to seek activities.
A typical human might have
about 50 nanograms per deciliter of dopamine.
When you're having a really bad day
and you can't get out of bed,
you might be around 40 deciliters if
you have a great meal
or if you have sex, right?
You might be around 90 deciliters
if you start taking addictive substances.
Right? Those get much higher, right?
Like a heroin or cocaine
is around four to 500.
Methamphetamines is over 1,000
And prolonged use of
dopamine accelerators will cause
the brain to adapt and respond and
prune off dopamine receptors.
Now what happens is when
without that stimulus that
accelerant your base line,
dopamine level can get very low.
People that are trapped
in addiction might have
a baseline dopamine level like around ten.
Now they're seeking the drug or
addictive substance not to get high anymore,
but to just function.
Because they've had effectively brain damage
with the loss of the dopamine receptors
that do not let them do that.
That's why there are chemical treatments
for helping people get off drugs.
Well, what we know is,
and the other thing I would tell you
about dopamine is what
happens is the first time you take
dopamine, okay, that's a surprise.
But then what your brain is attempting
to do is
your insula is involved
in encoding somatic states,
positive or negative, with
different actions that led
up to the dopamine response.
Right, the cues. And it
encodes that in long term memory.
This is what forces habit,
because you're conditioning the brain to have
a dopamine release at
the cues leading up to the drug.
This is what creates
habit and craving in people.
That is basically
the neuro biology of addiction.
What we know is that the use of
social media also
creates that dopamine release.
It occurs as you begin to think about seeing
message or something on social media
and you think about who
you're going to share it with.
Right codes that can become very addictive.
That's what happens when we say
people are getting addicted to
social media is not as
strong of an addiction
as controlled substances,
right, mind altering chemicals.
But definitely
meets the same biological definition
of addiction as food,
addiction as nicotine, as drugs as anything.
Moreover, though, we have
this need to be social,
a normal neuron, you see here on the left,
there's something called a von
economoeurons which tends to be much longer,
have fewer dendrites around it.
It seems to be highly correlated,
concentrated in
the anterior cingulate cortex,
which I show you here in blue on the picture.
What we think these neurons do is they
accelerate signals
across the large surface area
of our brain that we have.
What these are also involved in doing,
if you saw from the previous picture,
they are involved to
some degree in translating
the dopamine through to
the cortical areas of the brain as well.
We know that the surface area,
these are related
but unrelated things, right?
We know that the surface area of
the cerebral cortex correlates
with the size of the primary social group.
Robin Dunbar and anthropologist
showed that in a variety of
different primates and humans
infers that that's about 150 people.
What's interesting is when you
actually look at organizations,
organizations that have
150 people or less are
really considered small organizations where
everybody can know everybody
and know their skills.
But once you start exceeding 150,
it becomes impossible to
know everybody in the organization.
And you start needing
organizational structure to
help people access knowledge
and resources in the organization.
We also know that social exclusion.
When you think about being alone
or breaking up with a loved one, right?
It activates the same neural response.
Same area in the brain, in
the insula. As for physical pain.
I love this study from
Naomi Eisenberg and UCLA.
She showed
that college students going through
break up had the same activation areas in
their brain as people that were
having some other kind of pain.
When she treated them with
the stamp right, Tylenol,
she was able to show significant,
statistically significant reduction in pain.
There's two things that we can
actually emotional loss with
pharmaceuticals in the same way you
would treat pain for somebody going
through surgery or having
physical pain to the human, to the brain.
Even though logically we
don't like to think about this
biologically, we actually emotional,
emotional, we feel social loss and anxiety
as a much greater pain
than physical pain, typically.
So I think this ties into PTSD.
Before I was involved in neuroscience,
I did a large study.
A US Infantry Brigade
out of the Tenth Mount Division that
was deployed to Afghanistan.
This is 1,000 soldiers.
And we were able to do
full psychometric evaluation
prior to their deployment,
two to three months into their
deployment in Afghanistan and post
deployment so that we could
see the onset of PTSD,
depression, and unfortunately suicide.
What we found was that people that were on
the periphery of the social network, right,
were much more likely to
suffer increased rates of PTSD,
depression, and have stigmatic counseling.
Now, there's not a lot published on this.
I did a few presentations,
which is why I'm able to show
you the one image there.
Unfortunately, there was some IRB violations
and I don't need to go to
a lot of it, but I mean,
it involved one of
the investigators on the study
was court martial
doing some illegal activities.
Another individual, that was
the psychologist counselor on the project,
ended up being assigned to the very unit we
treated, that we studied.
And then he got
permission from two of
the battalion commanders to
treat soldiers that were highly
at risk to PTSD and depression.
And the other battalion
wouldn't allow him to do that.
There were unfortunately 18 suicides
in the battalions that he
was not allowed to treat.
There was none in the ones that he
was that created a huge scandal in the Army.
And unfortunately their decision
was that that was
an IRB violation and
we had to throw all the data away.
Very sad. But I do think
that there just hasn't been a lot
of studies that have investigated
that nexus between
social isolation and the pathology
of PTSD and depression and stigma.
That's actually a core area that I
found in the Brain Rights Foundation
to study and investigate.
You know, here's another view
of the impact that we have.
The importance we have on social connection
in all of this, right?
This shows you a study
of people in an organization.
It's a military platoon of military police.
And this is showing
you we took two different networks.
One was the respect network
of who do you respect in the organization?
The other one was friendship.
I don't remember which one this is,
but we can size the nodes here by
their relative rank or
prestige, if you would.
Then we selected
three nodes that were central.
You see one that doesn't
maybe look central in this network,
it's because it was probably
central in the other network.
But we tried to get people
that were central in both networks.
Peripheral in both networks.
And then we did a conformity study where we
were basically
presenting them with trivia questions.
Right? A part of your military promotion
is points based on
your knowledge of where's
building one on the military boast rank.
First aid, just
key knowledge questions, right?
As a portion of the points
that they get determined for your promotion,
people often will study
for those trivia tests.
Right? We use that test
where the people that were in green or blue,
green or red were sent on detail, right?
You're going to go on patrol
somewhere like to road
patrol like speed speeding tickets
or the front gate or do a
flag detail or whatever.
And then
the other black nodes are confederates
of this experiment on
one green or red node
would be in the group as they're
studying and then they agree
to give a wrong answer
on a subset of the questions.
And those were indicated by
slight alteration in the logo.
So people would know which
questions to say something wrong on.
This was my favorite question.
Right?
When is a tourniquet applied to a neck wound?
If you're not laughing at that, you
either don't know what
a tourniquet is or you're just not
really paying attention because
that's a funny question.
Right. But will be found is
that some people were highly,
were highly likely to
agree with the wrong answer. Oh yeah.
Tourniquet, where you cut
off the supply of blood.
You do that to your vein or
artery on a neck wound.
You strangle the person, you kill them.
One group was
highly willing to go along with that,
the other group not.
So I just want you to pause and say,
which group do you think is more likely to
conform to group pressure?
To a clearly wrong answer?
Is it the central actors?
Are they going to be
the ones that are going to conform?
Or is the peripheral actors just pause this,
jot your answer down before you hit Continue.
All right, you're ready for the answer.
Well, there was
a correlation between conformity and
between the centrality which you'll learn to
calculate in another module in the course,
negative 0.84 What that means is
central actors that have
social acceptance are not going to conform.
They're much more free to
think, to make their own decisions.
But people that are on the peripheral
are so in need of
social acceptance that they are much more
impressionable and much more
willing to conform, right?
This helps us understand
that people that do not have
social acceptance are in
a much higher state of influence.
A key factor that is affecting
their decisions is normative conformity.
And how do I fit in with
the group so that I can gain acceptance?
A little bit more of the studies that
we did in Jordan.
Again,
this is a picture of the device, right?
You'll see that they have a little cap
that's hooked up to a box.
The box about the size of a notebook.
We have computers that are observing
it, that we've studied that.
But here is an example of
a study Carolyn Parkinson did at Dartmouth.
What she did, she got a social network
of MBA students over three years.
Then the red dots are the
ones that she actually was able
to participate
in an MRI machine at the beginning of the,
their time in the graduate program.
She showed them just random videos
and measured brain response
across all areas of the brain.
Then she was able to
observe friendship formation that
occurred over whatever it is
two to three years of
their time in grad school.
Similarity in the neural
patterns in response to
just random images was
highly predictive of friendship formation.
What you're seeing is people that have
a social distance of one had
much higher correlations in
their neural patterns as
people that were a social distance of two.
And there was some negative correlation
in people that were three steps away.
And you'll see that four or more
is statistically the same as zero.
What's interesting about that is there's
a concept called neural horizon.
Network horizon, which is
where you know
the people you're connected to,
you might be aware of their friends, right?
The likelihood that you really know what's
going on a step behind that,
Beyond that at three is low past three,
it is completely unlikely
that you have any idea who the people are
or know them at all at
four plus steps, right?
They probably just haven't met,
they don't know each other.
You wouldn't expect that to be
much different than zero, right?
So it's a very interesting finding
that shows that friendship formation,
similarity, and neural response
are very tied together.
Let's bring this into neural marketing and
advertising in the late 1800s.
This predates neuroscience, right?
Lewis proposed a simple model of advertising.
He said that you first
need to capture somebody's attention.
Then you need to get their interest
to engage in the material.
You then need to invoke
desire before they will act for advertising,
We try and think of
a funnel where you
try and have maximum reach,
which is where the commercials are.
You try and do something in that
commercial to capture people's interest.
Qualify them as a prospect
before you can actually make the sale.
This is how we can think
of social media as well.
There are different methods
in neuro imaging to measure it.
Right, in the 1920s
when they came up with EEG,
and you might have heard
of some of these other ones.
Most recently has been
functional near infrared spectroscopy,
which is what I've been working with
as an optical imaging system.
It used to be about the size of a printer,
and we were able to miniaturize
the optic optics to get
it to a much smaller size,
the size like
a notebook or something like that.
The way it works is that
it is going to modulate light.
Like if you've ever had
a little alligator clip in
a hospital to measure
your blood oxygen level,
what we do is we modulate light
at two different wavelengths because
oxygen deoxygenated tissue
absorbs at different wavelengths.
Right? It allows us to measure
the oxygen deoxygenated tissue
that light is emitted.
Right? And it illuminates the brain.
And then there's a detector
that's going to detect
the passage of that light,
right, the two wavelengths through.
And then it can actually measure
brain activation from
a blood oxygen level dependent signal,
about two to 3 cm.
On the surface area of the brain doesn't
get at that deep brain area.
Where dopamine is, right,
it's very surface level.
But what's interesting for us is there's
a lot of brain
regions that are very important.
Counter arguing a empathy
motivation engagement
right from the medio prefrontal cortex.
It gives us a lot of powerful
tools for being able to measure.
What I'm now working on
is looking at facial expression recognition.
During covid neuromarketers were not able to
use EEG or FNR or these systems,
they had to resort to other means.
Facial expression recognition combined
with eye tracking has been very powerful.
It has enabled people to do
neuroscience studies
with just stable internet
and no actually touching of people.
What ends up happening with
facial expression recognition,
just to describe what happens,
is there's a visual input,
there is a perception of that visual input.
Then we oftentimes have a mimicking of that.
We have mirror neurons
that mimic the thing that we've seen,
which is that physiological response,
which we then interpret as
an emotion or an emotional state.
Right, This is how facial
expression recognition occurs in the brain.
And there's a reference
there if you want to study more of it.
What we've done with computer vision
is we can take a sequence of images.
We can augment it with different scaling,
rotation, colors, noises, right?
To improve that, we can normalize the face.
Then we can run it through
a convolutional neural network, right?
Which is different layers of processing
to help us understand is that Contempt,
discuss, fear, happy, neutral, sad, surprise.
Probably about 16 different emotions
that people can reliably test.
And there is competitions
that have been done on this
over various times with
the facial expression recognition.
What we can do is we can really get at some
of the deep brain emotional response.
Which as you recall, is
probably more important from
a sales and marketing perspective
than decision making.
We're going to go into a
little bit more about how
that is useful in future lectures.
But I hope you have enjoyed
this deeper dive into understanding how
the brain responds to stimulus,
both emotional and social.
I think understanding those mechanisms help
us think about the social
part of social media.
Why it's so important,
and why it's so ubiquitous in our society.

Hello, I'm Dr. Mcculloch.
We're going to talk a little bit more in
depth about narrative transport.
So take a moment to look at this.
A lot of times content
on social media involve
a quote or something
next to a well known figure.
Our brains just naturally
want to turn that into
a plausible story even if it's on face value.
Somewhat absurd,
Practicing narrative immersion
is an interesting topic, right?
It's more effective at
overcoming counter arguing
and actually getting your stories believed.
It's not necessarily
a full blown story, right?
It can be a meme
that communicates something with it, right?
But what, a lot of times the stories do,
they do several things, right?
They create camouflage
for our persuasive arguments.
So people think, oh,
we're just trying to entertain or be funny.
And so they don't necessarily know or
identify the persuasive message
or argument that's underneath it.
They can create cognitive dissonance.
Cognitive dissonance
is when people are holding
two conflicting views at the same time.
It's really hard to
do that for people, right?
They want to either reject one
and accept the other or try and
find a way to bring them together because
they don't like having
these dissonant beliefs.
When people identify or relate to
certain characters that hold
counter attitude and beliefs,
then it's almost easier to change
attitude than it is to
reject a character that they identify with.
The way that's done in persuasive narrative
is you'll present a character and
you really build the details
and you really help the viewer
identify with the character and relate to
that character the more they bond
with the idea of that character.
Then when it's revealed that
the character has these counter
attitudinal beliefs,
that's where you actually get the narrative.
Transport stories can be
entertaining and capture attention.
Like if you think about that model of
advertising, right, capturing attention.
The more engaging the story is,
the more entertaining the story is,
the more you're capturing attention up front.
And moving them down the funnel of
marketing stories also explain
our identity and our social norms,
which as we saw in the neuroscience piece,
is our brains are wired for that.
Where they're wired for social norms
at the core of our identity theory.
The stories also compose heroes and villains
and define good bad in our minds.
They are grounded often in like moral views
that compel or justify our actions.
Right, all of these things come together
in this idea of creating narrative emerging.
The first key concept is testing stories.
There are four components to this narrative.
Probability,
what's the likelihood that
the story could occur?
And you can set conditions like a,
we're in space or we're in an ancient time,
or there's dragons, or you
can define that up front and be pretty crazy.
But within the parameters
you've said at the beginning of the story,
the story needs to flow in
a plausible way that it's
actually likely that this is happening.
It needs to have consistency.
The characters in the story need to
act much the same way, right?
You can't have them having
two totally different
personalities and behaviors.
The more you account for actual facts,
the better you are.
What was showing in the upper right
here is come as a pizza joint.
A few years ago, there was a man that
came with weapons, right?
He had pistols and rifle.
And he busted into this pizza joint
because he thought that there was
a child sex trafficking ring
run by Hillary Clinton in
the basement of this pizza joint.
And he was there to liberate the kids and
save the kids from human trafficking.
This pizza joint had no basement.
It was complete fake news,
but the Hillary Clinton
was having a sex trafficking ring.
What was not fake news is that a man
actually took action to come in there.
And it begs the question, why
was an individual from
fake news he saw on
line actually willing to
take such extreme action?
But when you start looking at the case,
right, he actually had narrative probability.
Even though he had
probably conservative views.
It totally made sense
to him that Hillary Clinton
would be running a sex
trafficking ring, I guess, right?
It was totally coherent
with how he viewed her as a character,
that this was plausible.
Then it leads to some real world action like
that when we're looking
at stories that we want to persuade people,
fake news or otherwise, right?
Having that narrative probability,
fidelity, coherence of
characters and actual facts.
Some level of actual facts there was
an actual pizza joint is important.
People also are going to
have confirmation bias, right?
They are going to preserve as
much as they can pre existing beliefs.
It's very hard to get people to
reject beliefs that they've
had the longer they've had it.
There's this definite like my side bias.
And you don't need the best argument
for views that are on my side.
You just need minimally sufficient and people
are very quick to affirm self worth.
They're very critical of others and they're
very motivated to scapegoat other people.
Right? These all feed into
the confirmation bias when
you're looking at the
picture on the lower right.
Right? What does that say to you?
Right? And I think that's just funny,
but our biases, right,
are actually going to affect
how we read that sentence
and how we interpret it.
As we discussed earlier,
people respond to emotions.
Decision making is based on emotion,
it's not based on
rational thought and evaluation.
Our brains are relatively lazy.
We don't like to invoke our system to,
to actually evaluate information
and make informed decisions.
We much prefer to go off of our gut.
That's just the way our biology is,
wired and so we're basing that on emotions.
People aren't going to attend to
the argument unless they capture attention.
That's why you might see the
commercial of the baby
talking of some just
really crazy, absurd thing.
They're trying to capture your attention
so that you'll attend to the message, right?
There is a strong relationship
between news and entertainment.
People would much rather get their news from
an entertaining source than one where
they have to read and think and evaluate.
This is part of the reason why there is
such strong appeal for conspiracies.
One of the students taking this course
a few years ago actually
did a paper on conspiracies.
And he looked at a bunch of
different conspiracy theories that he
found on line was
surprised at how people that believe
in one conspiracy theory
are much more likely to believe in others.
And that there was actually
a network of people that were
more susceptible conspiracy theories
in the first place.
Fake news captures attention,
especially with that moniker,
Fake news, right?
It takes advantage of
our pre existing prejudice.
It appeals to our anxiety and
our fear and draws
on that whole conspiracy money.
The attention often creates ad money.
The way social media platforms have
evolved is anything
that draws your attention,
draws value for advertising funds.
Because think about that advertising funnel,
right?
The advertisers think that
the first thing I got to do is
grab your attention, then get your interest.
And then that funnels down to your action to
buy if they can
tap into content or
personas on line or
influencers that already have the attention.
It's not that people are
actually convincing you to
change behavior in some way,
but can they capitalize
on the fact that certain personas online have
high attention that can actually draw people
to the site to be more
likely to see the ad, to be aware of it.
We talked a little bit about this before,
but the social media impact,
right, People are drawn into echo chambers.
There's a lot of new media options,
whether it's like cable news and talk radio
on demand on programming.
But then you also have like Internet,
Twitter, app, social media.
They're all made of other users
like us so that there's a
greater sense of authenticity.
And it is almost more trustworthy than
the conspiracy that there's
some elite group of
people that are shaping the news.
That we're going to listen to,
a way to manipulate or influence us, right?
The information sharing that
we do on line is viral.
And we talked about the dopamine system.
And as we think
about content that we
see and who we can share it with,
we get that release of dopamine
which addicts us to social media.
There's also the media landscape,
like what are the messages that are
circling around that we're
more likely to come across and share?
Are we prepared for counter arguing, right?
Is there a tension between fake news
going unchallenged and
a counter arguing response?
I talked about that in
a previous lecture, where
When I would ask the question,
should a politician that is being criticized
by their opponent or having fake news,
or fake rumors spread about them,
should they respond to them?
We have this gut feeling
that we got to correct the record.
We got to set the record straight,
we got to correct the information.
But empirical evidence suggests
that that might just be
creating a counter arguing
response and going the opposite direction.
What are some of
the advanced tactics that you can do?
Can you redirect people?
The more compelling content When Russia
had shot down a
passenger aircraft during one of the,
I think it was the Crimean Crisis.
All right, What they did is they
flooded the internet with tons
of information about celebrity gossip
and it completely captured
the attention of social media
away from the fact that
their military had shot
down a civilian airliner.
Suppressing it in the larger media
wasn't a story that got traction.
Redirecting, overwhelming people
with alternative content can
be an interesting way of shaping
the media landscape as well, right?
To things that are going to be
more compelling for people.
When we're countering narratives, right?
The counter narratives,
they need a basis in existing beliefs.
If you don't have some existing
beliefs to grow from,
the likelihood that you're
actually going to gain
traction is very low.
People are very suspicious
of those providing counter evidence.
The more you can have a trusted source
providing the counter evidence, the better.
This is part of the appeal of deep fakes.
Right to appear to be a trusted person.
It's unclear the extent to which that can
backfire successful counter narratives.
When you're trying to
change people's opinions,
they focus on the motives of the promoters.
Remember I said attack the source.
They focus on the motives of promoters.
They portray information as a weapon.
They use history to create motives,
and they demonstrate narrative inconsistency.
Probably one of the most recent examples
is if you look at US politics,
which seems to be a great natural laboratory
for understanding social media.
I'll look at two different presidents,
so that I'm not politically biased.
But when you look at Donald Trump,
is anybody really criticizing
the policies of Donald Trump?
His programs, his actions,
or do they tend to focus
on the man and the candidate?
Right? And trying to paint
information as a weapon and trying to
create analogies or similarities to
evil people in history.
That he must be like to
try and attack the source.
Similarly, most of the criticisms of
President Biden are focused
on, on his speech.
Right?
I think his public
speaking ability has obviously
degraded between when he
was Vice President and now President.
So they're going to attack his failing age,
his public speaking abilities,
his movements, right, They're attacking him.
And it's almost more personal in
the attacks on President Biden,
but they're not really focused on his issues.
I suppose the only exception
to that is there is probably
criticism on issues of
border security and probably of
how handling Covid and
a couple of those issues.
I would argue that the majority
of the comments are attacking the man.
Right.
Again,
successful counter arguments is you can
take a President's policies
that are objectively have failed,
but a supporter of
that presidential candidate
is not going to believe it,
buy it, or accept it.
There was a study that was done
about oil prices,
this was between Bush and Obama.
When George W Bush was President,
they asked Republicans and Democrats,
as, does the President have
an ability to influence
policy affecting the price of oil?
When Bush was the president,
only 25% of Republicans thought that
the president in his office
could affect the price of oil.
75% of Democrats thought
the President could affect the price of oil.
When Obama was President,
was the President that flipped?
And only 25% of
Democrats thought the President
could affect the price of oil.
75% of Republicans could.
We're biased in our view
of what a particular office or
power or capability has
based on our pre existing views and beliefs.
We talked about the power of narrative and
the neurocognitive influence model
in a previous lecture.
So I'm not going to go into detail,
but our goal when we are attempting to
change belief or advertise
or influence on line.
Or maybe it's not you trying to do it,
maybe it's you being aware of how
others are doing it and what's effective.
Essentially, the most effective route is
to create this narrative immersion
in this narrative transport
that is correlated with
self integration and affects
behavior change while preventing
or blocking counter arguing messages.
That's the ultimate goal. How can we do that?
Well, Kendall Haven during
the Darpa Narrative Networks program
identified
eight essential elements of
a story structure to
create narrative transport.
The first is the characters.
There's maybe a main character,
there's supporting characters,
but in that there is
an identity character and
the identity character is the one
that is positioned
to create narrative transport.
Each of the characters
are going to have traits.
So these are elements of
their character description
that's going to be
used to control the viewer or
the receiver's attitude toward or
the relationship to the story characters,
right?
What do you think of them? It's the traits.
There is a goal of what the
character needs or wants to
get in the story. There's motives.
This is creating that narrative
plausibility motive
matching is a key tool for
creating a target audiences identity with
an empathy for specific characters, right?
We know that goal and motive
matching is actually
stronger at creating identification
with characters than traits.
Through the story arc,
there are going to be conflicts and problems,
obstacles between
the character and their goals.
And the more engaging
those are with risk and danger,
the more engaging the story is,
the more exciting it is,
the more you're going to draw
attention for
the viewer, there are struggles.
These are the sequence
of events that the character
undertakes to ultimately reach
the goal in the climax scene.
And then there's either
going to be success or failure, right?
That's like the climax event.
And then there's a resolution scene.
Then all the other details
are just adding imagery
to draw people in
and engage them in the story.
How does this work? Well, there's
an identity character and as I said,
goal and motive matching
is more important than I,
than trait matching for identity.
Although trait matching is important,
familiar settings
help you create the character.
It's better when it's the main character,
but it doesn't have to be.
If you think of Star Wars, right?
If you've watched the movie Star Wars,
I picked that because it's probably
the most watched movie of our generation.
Who do you identify with as a character?
Do identify with Luke Skywalker?
Many people. Hanslo, maybe Princess Le.
I've heard some people say
nobody ever identifies with
C three PO or two T two.
But who you identify with right,
is going to affect how you
are influenced
by the story arch of that story.
Okay, there are goals.
The goals are tangible.
The more they contrast success or failure,
the more effective they are.
Being effective in the story
for narrative transport,
Those motives are right,
how we're going to get to the goal.
The motives should be culturally appropriate.
You want your motives to lack detail because
contrast is created when there's high detail.
What people do when there's
a high level of detail,
they think of all the things that are wrong
or inconsistent with their existing views.
When you lack detail,
people tend to have greater assimilation
where they tend to feel
that it's more like what they
think or what they believe or
their own biases creep in.
That's why effective politicians
lack specific positions on key policies.
Because it leads to assimilation,
where people are more likely to
identify with them and vote for them.
The less detail that they
present then the obstacle or the antagonist,
right, needs to be tangible.
The greater the risk and danger,
the more engagement that people
have with the story, right?
You want to have some high level of contrast,
because you don't want the people to
identify with the obstacle or antagonist.
You want them to be clear about how it
is preventing the character
from achieving their goals.
There's a climax scene,
this is where the hero or
villain can either be positive or negative.
Affinity, right is going
to determine the outcome of the story.
When the identity character
is the person that's affecting the outcome,
you get this great sense
of efficacy amongst people.
But when you're not the hero in
your own story, right,
it actually causes
this detachment or this lack
of empowerment and
it immobilizes action, right?
So it doesn't really move you to action.
There's an example Haven uses,
where he talks about a scene of
the story where John Wayne is going across,
and they've circle the wagons,
and the Native Americans are attacking.
And it appears there's no hope,
they're out of ammo.
And then the cavalry comes
over the charge and rescues them.
Well, when you have identified with
John Wayne as the identity character
and you have an event like that,
it is it lacks empowerment.
You might identify with John Wayne,
you might have narrative transport for him.
But that specific action of
efficacy to change behavior is gone.
That efficacy is really,
really important because if
you're trying to change behavior,
people don't have efficacy.
There will be no change,
even when we think
about social problems, right?
If people don't feel that they are empowered
to make a change in their life
and to change their outcome,
that it's maybe the government's
responsibility to step in and do it.
You will never have change because you
basically rob the people that
are affected of their personal empowerment
and efficacy to achieve change.
The resolution is also important.
This is
the emotional imprint and called action.
What we find is if there is no resolution,
maybe we've seen a movie
that just doesn't have an ending,
it's just left unresolved.
People tend to just delete everything
from memory and it has no effect.
If it is a positive ending, a happy ending,
which is common of many western movies,
then there is low arousal,
but it's a longer duration arousal
and it makes a positive impact.
If there is a negative outcome,
an unfair bad ending,
then there's a much higher arousal and
a much greater call to
action to do something.
And I would say that we can also
see elements of
this not just in
full movies but in other stories,
even when you see a meme,
these elements are at play in
trying to affect people.
What was really I think fascinating about
Havens approach in
the dark and narrative networks project
is by defining these factors creates
variables that you can
change The varying levels of identity,
of goals, of detail, et cetera.
And you can then alter them in
a statistically designed
experiments to understand
their impact on influence and what
you need to tune to make
a message more or less persuasive.
How does this get tied into neural marketing?
Right? I'll give you another view, right?
It doesn't have to be as complicated as
I mentioned in
the Darpa Narrative Networks project,
right?
If you look at sales brain,
their basic proposition is
a single ad, right?
And this is a static ad
that could be delivered online.
You could also think of it as
an analogy to a mean that
the ad needs to
trigger something in the primal system,
one brain and emotional response, right?
And then it needs
to invoke enough interest and
attention for your prefrontal cortex
to say, hey, I need this.
I'm going to actually take action.
Where neuromarketing has evolved
to is initially eye fixations.
Can I use eye tracking to identify
what areas of the ad
are actually being viewed?
And you'll see that that face
is a key area that jumps out to me,
even in that darkened image.
Well, what's that saying?
It's saying that we are drawn
to identity characters.
We also read that there
is somebody reading what you could
leave bad hair days, right?
Like you're seeing that they start
reading it but see how it wanes off.
People just start reading it and
it's not fully capturing their attention.
You see that they're
probably capturing nourished.
And it's very quick glance, right?
The face is what gets most of the attention,
the emotion that, that face presents.
If you remember the lecture
on how the brain responds to
facial expressions, we mirror that.
If you have an expressive actor
that's going to actually mirror
the feelings you have towards
that ad and it's going to
then shape how you're
activating in that primal brain.
Sales brain offers actually
six different areas of which you
can tune to make
an ad or a meme more effective, right?
So they would say, is it personal,
is it contrastileangible memorable?
Is it visual? Is it emotional, right?
Those are like the six components
to make an effective ad
if you're designing it.
What we've covered in
this lecture is we've
gone a little bit about more
into narrative transport.
And we've talked about what some of
the essential considerations are when
you are evaluating
the potential impact or effectiveness of
a narrative or a meme or a campaign.
What you would need to design
into it if you were going to
make one that was effective yourself.
And how some of that maybe affects
current world events and political discourse.
I hope you enjoy this lecture,
and I hope that your brain is firing on
all the different ways in
which content can be more or less effective.

Hello, I'm Dr. Mccullough.
In this lecture, we're going to be talking
about platform manipulation and intervention.
How platforms are
moderating influential content.
There was a project I was doing at
the Applied Physics Lab for
the Office and Naval Research.
And one of my students wanted to reverse
engineer Twitter's
front page algorithm because
the way content is presented to you
is not necessarily in
the order in which it comes, right.
It's being tailored in some way,
recommended to you, which
is not malicious in any sense.
The value of a social media platform
is the amount of users
that are on it and engaged with it.
The more users that are engaged with content,
the more valuable the platform.
So of course, the company, the platform,
is going to spend a lot of money
and effort and time and thought
into how to keep people
engaged and attracted to the platform.
We found that like reverse engineering,
the front page algorithm
is next to impossible, right?
We don't have that. What she did is she did
a data poll of all the news articles, right?
That in Wired magazine,
Slate.com All these things,
interviews with front page engineers to
identify what they said
were factors that went into that.
And we've organized it into six categories.
One about the engagements, right?
Like the number of interactions you have.
The strength of relationships with other,
other actors on line where it was originated.
If there's a geo location of that,
right, All of those things, right?
The number of retweets mentions, favorites,
replies that the ad has like that is
going to affect its popularity, right?
Number of your engagements
that is going to affect it.
For the type of media,
we know that video is
more engaging than image.
Is more engaging than a link.
Is more engaging than content
like text, right?
If you can put like a video,
you're going to have a lot more attention
than if you have a meme.
Than if you're just having
a single tweet of characters.
The tweets popularity is
also going to affect
not just your engagement,
but like if the tweet itself
is getting a lot of attention,
then it'll be presented to you.
There is an element of
recency like when it was created.
What the pattern of life for you and
the content are Shared connections.
If it's getting a lot of traction with
people in your network and
your friend follower network,
then it will be more
likely to be presented to you.
Then there's also audience behavior,
you as a user, right?
What is your frequency?
What have you engaged in the past?
How much time do you spend reading
other similar content, right?
The point here is that there
are a lot of factors going
into what gets seen
on a social media platform.
The message itself, what's
really alarming is if you look at
a typical Nato or US
government response to Kring disinformation,
the joke is that
it is easier to get approval to
drop a missile on
someone than it is to send them a tweet.
Because people are so afraid of
the media backlash that it really
limits your ability to
send messages out at volume.
Well, that's not the case
of malign nation states
like Russia or
People's Republic of China, right?
Where they will send messages out at volume.
If something's
incorrect or wrong or whatever,
it's just going to get overwhelmed
with the other content that's out there.
As a result, when you look at influence on
European viewers, for example,
my estimates are that Russia has got
500 to one amplification on
their messages over Nato
messaging on their audiences.
Because of this fact,
what are some of the things they do?
Well, you'd say that Russia
will have dozens of state
sponsored social media accounts
that like each other's content,
that you engage in each other's content,
they will tend to have
more images and videos.
They will tend to use
bots to artificially increase
the popularity of their content.
In doing that, they basically
trick the platform into
promoting their content.
Not because the platform wants to,
but because they've just
studied and understood how
the dynamics occur so
that they get the message out more.
Whereas Nato doesn't even
seem to have the ability to
like each other's content,
or even have coordinated accounts
within the same office or same organization.
And then it really suppresses
the ability of that message.
You may not be doing
this for political reasons,
but if you're thinking about an ad
campaign or media campaign,
what types of things can you
do to have multiple reinforcing accounts?
What can you do to understand
these different factors that go
into front page popularity?
Are they different
across different platforms?
Can you get a sense for that?
Can you do something to take advantage of it,
to promote your content and get it out there?
We're going to turn our attention a
little bit to firestorm behavior.
Firestorm is a large negative word
of mouth campaign on line.
A couple examples that
you're seeing over here on the right
is Cancel Bert Bert.
Us celebrity talk show host and
he said something made fun of,
it's like an Asian slur that he
was doing to make fun of something.
There was a person online that took offense
and it launched as
a large negative word
of mouth campaign on covert.
And you'll see that
there's that initial spike,
it fades off, There's some attention.
Second spike occurred like
the firestorm that almost
died out when he
was announced to be taking
over for David Letterman.
And then that reinsured,
reinvigorated it for a short time,
and then it died off again.
Hashtag, My Nypd was a campaign launched by
the New York Police Department to
show pictures of cops
helping out their community.
And it was to try and
promote positive feelings
towards police in New York,
but it was quickly hijacked and flooded with
images of police brutality
and other things, right?
Which then created a firestorm
and a lot of negative attention towards them,
so they eventually just stopped using it.
Right? So that's an example of firestorms,
and it can either be in
response to some event
or sometimes people can be doing something
positive and their hash tag gets hijacked.
Right?
There are a variety of
different ways in which that occurs.
This is when a small number of users
are responsible for the majority
of the tweets we find, right,
there's a small group and
they tend to have high volume,
but the media hypes are self
reinforcing the fact that
more people are using it,
more people want to be included.
Think back to that social
behavior that we're hired wired for.
They want to get involved and
share content on it and share it with others.
It becomes the popular thing to
do and it creates this big spike.
It's usually driven more
by the discussion and the
type of discussions going on,
the reactions people are getting,
and less by the actual events.
There's a huge lag time for apologies.
The most interesting thing about
firestorms is they don't last right?
You're seeing
that distribution in the bottom.
The average firestorm only lasts
a couple days and then it dies out.
You're responding to it again.
This goes back to
that counter arguing argument.
We have this gut feeling that we have to
respond to disinformation or
correct rumors or set the record straight.
What we find empirically is that firestorms,
and that's a very extreme version
of rumor or misinformation,
we find that get
attention for a couple of days
and they die out.
The attention that they're
getting is more about
people just engaging in a social process.
In a social community,
having something to share
other people with to
satisfy their dopamine response.
It's the sharing, not the
content that's really driving the behavior.
If we then respond to it,
not only do we risk counter arguing,
but we're likely to prolong it.
We're likely to actually instigate people
bringing in counter arguments
into the discussion and the discourse.
And then it's going to actually get
more traction than if we just let it die out.
This is another reason why
it's generally better to not
respond to the actual rumor
of the allegation itself.
It's better to reframe or find
more compelling content to
dominate the conversation.
There's another concept that we'd like to
talk about called majority illusion.
What you see is
the two networks are the same.
The red nodes represent a minority viewpoint,
the white nodes represent
the majority viewpoint.
When you look at a given network,
you don't get to survey everybody in
the network to understand
what their opinion is.
You only really get to ask
the people that you're connected to.
If we look at the percentage of
first order connections for a given actor,
have the red view
for the network on the left,
you'll see that pretty much everybody thinks
that most people in the network
have the minority viewpoint.
That's what you're seeing in the table there.
For the network on the left. The network on
the right has a much more accurate
view of the network, right,
where two people think that
as many as half the people
have the minority view,
but it's
a much more generally appropriate view
of attitudes in the network.
Lehman shows that there's two properties
and networks that affect majority illusion.
One is the assortativity network.
An assortative network is
when highly popular nodes tend to
be connected to nodes
with few followers and low degree,
as opposed to a more even assortment
across the network.
Then the other property is when
the high degree nodes
have the minority opinion.
The reason why this creates
an influence effect is because of
a social psychology concept
called pluralistic ignorance.
It's not the norm that drives
behavior as much as
the perception of the norm.
They've tested this on a lot of
college campuses because that's
what social psychologists do.
But if you ask college student
how many beers they drink at a party.
The typical college students
says three to four.
But if you ask them how many,
everybody else that the party is drinking,
they'll say six to eight.
We find that in
college students
perceive that everybody else is
drinking twice as much as they
are doing twice as much illicit drugs as
they are having twice as
much premarital sex as they are.
What ends up happening is
that perception of the norm
drives higher levels
of drinking and sex
in college than in the general population.
Once they leave college,
they have a different view of
what the societal norms are.
And then they go back to
a more moderate level of
behavior, that's pluralistic ignorance.
When we achieve a majority illusion on line,
we believe that it has an ability to achieve
pluralistic ignorance
on the part of the viewer
that may shift social
norms and normative behavior.
Well, what do we know about social media
tends to be dominated by celebrities
or influencers who tend
to have minority political views.
But it leads to the belief that
that minority political view
is actually a majority and
causes us to be surprised
when we see things in the media,
like Donald Trump receiving
as many votes as he does
in a primary or in an election,
or other political votes
that don't necessarily match with what
we think they should be. Why?
Because our perception of viewpoints
of voters is based
on what we see on social media,
which has a high level of
majority bias
towards a more liberal point of view.
And that's not to take
a political stand in this.
I'm just pointing out how
majority affects
decision making and influence
and how it might manifest as it
relates to political discourse
in US politics today.
Another thing that we're talking
about politics here is dormant bots.
Dormant bots are defined as a social media
account with high followers
but no content generation.
What we did in the
2018 midterm elections is we looked at
all of the followers
of Congressmen running for election.
When were those Twitter accounts created?
We found that there were two
spikes or anomalous spikes.
One dated around the time where people
were finding out about Twitter and
establishing their initial accounts.
But the other spike highlighted here in red
occurred shortly
after the inauguration of Donald Trump.
We notice for those accounts
that were created in January 2017.
When we look at the joint distribution
of followers, friends,
and posts, we see that
the normal behavior has
a healthy mix of those sorts of things.
Right? Some people are posting a lot more.
But what we thought was very
unusual was where
these accounts were being created that
had lots of followers and
many of them had never posted anything.
Ever led us to a question,
Why would somebody follow an account
that Denver says anything or does anything?
Well, when you look at the social network
of where they're positioned,
they are positioned in such
a way that they totally
manipulate platform
recommender system to amplify,
in this case, one political
party's Twitter
messages and suppress the other.
What do we do with this? We took
to Twitter, they weren't interested.
Initially, we took it to the FBI,
who then ordered a court injunction that
required them to ban all
of the dormant bought accounts.
This was several months before
the 2018 election that resulted in
a 7% suspension of
global Twitter activity and
a 23% drop in
the short term drop in their stock price,
and defended the integrity
of the US elections.
Now Twitter actively
implements similar algorithms and
more sophisticated algorithms to
prevent the presence of dormant bots on line.
That's not to say that there's not
a similar account or
something like that that's out there,
but that's just an example
of how you can create bots,
not necessarily to generate content,
but bots to shape the way
the platform recommender systems
work to affect attention,
interest,
and engagement within your accounts.
And that's actually much more
sophisticated and common tactics
than others when we're
looking at these influencers, right?
Or as discussed in
literature, opinion leaders.
There's many different types
of opinion leaders and we can
discuss this more after we
get into social networks a little bit.
But what this shows is
the effectiveness of influencers.
What you can see a celebrities
that maybe have tons of followers.
They are really good at getting awareness of
something out there because of the
large scale of their followers.
But they don't actually change
people's opinions or mind.
People know what
an influencer of celebrity is doing,
and they're not very persuasive typically.
Sociometric is where you
have somebody that's influential within
a social group that you
ascribe to remember we're social creatures.
We have that need as
we're belonging to a group.
People that occupy
central positions in that group.
They are the ones that have more influence.
And it is a myth that the influence
somebody has in a tight social group
of friends, that somebody is central there.
That a celebrity is going to have
a similar set of power
to a larger scale of people.
That doesn't happen, right?
It degrades and it becomes
diluted as you get larger and larger, right?
You can pause on this and you
can study this a little bit more.
If you're interested in opinion
leadership and how it goes.
It is beyond the scope of
what we're going to discuss in this course.
So when we think about
how influence works and
the role of leaders in
the adoption process, right?
This is
just a simple public health model that
I think is very applicable on line, right?
There's six steps in
the product adoption process, right?
The first one is that awareness interest,
we talked about that from
the advertising model as well.
This is where somebody that is high in
degree or has a lot of connections, right,
Is helpful because it
builds awareness and it builds
interest for people to
learn more and seek more information.
But then you have to start moving away
from these high celebrity
type opinion leaders.
More to opinion leaders
are more well defined in a social groups,
you need to move away from like
national level opinion leaders when you go to
the next steps of
this persuasion evaluation, right?
This is where you're trying
to talk others into
gathering information and considering use,
making a decision to try
something and test it out. Right?
This is where you need to start
getting into more regional opinion leaders
or local opinion leaders or
peer opinion leaders to make those decisions.
And then when you get into adoption,
you're actually going to compare
your personal experience and
expectations with future use.
And then conformation,
where you're going to continue
to use whatever the product is,
advocate for it amongst your social networks,
like word of mouth, right?
The network data in social network measures,
which we're going to talk about
in a later lecture,
is going to get us to that top layer.
That last mile is
going to get that last mile
in adoption and use.
I think that's an important
point because a lot of
social media vendors and
providers will use very simple,
easy to calculate metrics that
have a lot of national flare,
which is really only getting at that block
1.2 They're never really
getting to the point of understanding
how social networks on line,
moderate influence and actually get
you to that last mile
of adoption and confirmation.
That's why we're going to spend
a lot of time in the first part of the course
really understanding social networks
and why I'm pushing
a lot of the social theory
upfront so that when we
start getting data and when we start
looking at like machine
learning methods
to understand and reason over the data,
we're doing it from
a more theoretically grounded perspective
so that we can make
better inference and better decisions.
I'm going to conclude this
with just a simple model of
behavior change that I
think is
the most complex model
that's easily understood.
In this, the BI
represents behavioral intention.
This is a heuristic equation.
It's not meant to be empirically derived,
but it helps you
reason about what's happening.
Based on all these theories,
behavioral intention,
intention to do behavior
is the best predictor of
actual behavior and it
is a function of attitudinal beliefs.
So think about what we talked
about with belief formation.
Belief echoes inoculation,
social judgment theory,
all of these things, right,
are all going into attitudinal beliefs.
The general attitudes and beliefs you have
about a given behavior issue.
The IN is injunctive norms.
That's really what we're just talking about,
about opinion leaders and
influential actors
in a network, within a social network.
The descriptive norms are
like the peer influence.
Think of what we've talked about with
peer pressure group pressures,
normative impacts on people.
All of those get
moderated by behavioral control.
Do you feel like you're
the hero in your own story?
Think about that narrative transport.
Does the identity character end up being
the climax character that can
change the story? Or do they have no power?
And it's somebody else
that has the power in the story.
If you have no efficacy,
it doesn't matter how much
you work on these other factors.
You're not going to change behavior,
You have to have efficacy to change behavior.
When we look at how we measure
these factors that might
inform behavior change, well,
opinion polls or there
are certain things we can do in
natural language processing or
observed behavior of actors
to understand attitudinal belief and
efficacy in understanding
opinion leadership and subgroup analysis.
Right,
For injunctive norms and descriptive norms,
you really need social networks.
And we're going to spend a significant
amount of time really
understanding how to calculate
social networks and how those measures work.
What that understanding does is it gives you
four groupings of tactics
that you can use to change and move behavior.
You can think about attitude and beliefs.
Am I going to introduce new beliefs?
Change current beliefs? The importance
of beliefs going
to create belief echoes in injunctive norms.
Right? It's all about opinion leaders.
Can I co opt an opinion leader?
Create an opinion leader, remove one?
Shaping majority illusion actually tends to
help shape certain opinion leaders in
the network that might
have greater influential effect.
Can I shape the network in
some way to make
an actor that is not
otherwise an opinion leader,
an opinion leader that
people listen to, right?
And then the same way we can look at
other factors to target
influence based on this model.
A lot of the things you see on line
are actually targeting
this model in some way.
If you see memes, right, that are meant.
This is a meme on the left.
It goes back to that Obama birth certificate
we were talking about earlier, right?
That is a mean, attempting
to create a belief echo,
even though the rumor can be corrected,
the belief echo can leave you in
negative opinions of President Obama.
One of the first deep fakes
was of President Obama.
And it allows us to create or
co opt an opinion leader and have him
advocate things that he may
not actually believe or
espouse what you're seeing
under descriptive norms.
An example of synthetic images,
that is basically fake people
that have been created where one person
is a real respondent and you might think of
a chat form to manufacture
descriptive norms that don't exist.
The behavioral control
is spotlighting success, right?
Or framing victims to
affect their efficacy, right?
If you're the victim
of some big conspiracy
or some big government,
your level of efficacy
and behavioral control goes
down and your likelihood to
act is diminished.
When you see people that
you identify with taking
action and actually doing
a pro attitudinal behavior,
then it encourages you to
actually adopt and act that behavior as well.
All right, so we've
covered a lot over this module.
A lot of it has been
focused on social theory,
neuroscience, persuasion and influence.
And we've discussed a little bit
about how that's been moderated online.
I hope you've enjoyed this content
and I hope that you'll enjoy
the discussions that we're going to get
into as part of
the assignments for this module.